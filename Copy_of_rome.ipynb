{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Xodarap/notebooks/blob/main/Copy_of_rome.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b13177b7",
      "metadata": {
        "id": "b13177b7"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmeng01/rome/blob/main/notebooks/rome.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" align=\"left\"/></a>&nbsp;or in a local notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5416767c",
      "metadata": {
        "id": "5416767c"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "!(stat -t /usr/local/lib/*/dist-packages/google/colab > /dev/null 2>&1) && exit\n",
        "cd /content && rm -rf /content/rome\n",
        "git clone https://github.com/kmeng01/rome rome > install.log 2>&1\n",
        "# pip install -r /content/rome/scripts/colab_reqs/rome.txt >> install.log 2>&1\n",
        "pip install --upgrade google-cloud-storage >> install.log 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.28.1 python-dotenv==0.19.2 datasets==1.18.3 accelerate faker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCqjxEUwxl-D",
        "outputId": "ae04b2fd-3239-4e73-91b7-e9413708deef"
      },
      "id": "VCqjxEUwxl-D",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers==4.28.1 in /usr/local/lib/python3.10/dist-packages (4.28.1)\n",
            "Requirement already satisfied: python-dotenv==0.19.2 in /usr/local/lib/python3.10/dist-packages (0.19.2)\n",
            "Requirement already satisfied: datasets==1.18.3 in /usr/local/lib/python3.10/dist-packages (1.18.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.18.0)\n",
            "Requirement already satisfied: faker in /usr/local/lib/python3.10/dist-packages (18.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (2.27.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (3.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (4.65.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (2022.10.31)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (0.14.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (0.13.3)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from datasets==1.18.3) (0.3.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==1.18.3) (3.2.0)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==1.18.3) (9.0.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from datasets==1.18.3) (2023.4.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==1.18.3) (3.8.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==1.18.3) (1.5.3)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets==1.18.3) (0.70.14)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.0+cu118)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.10/dist-packages (from faker) (2.8.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==1.18.3) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==1.18.3) (1.9.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==1.18.3) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==1.18.3) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==1.18.3) (6.0.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==1.18.3) (1.3.3)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==1.18.3) (2.0.12)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.1) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.4->faker) (1.16.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1) (1.26.15)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4.0->accelerate) (16.0.2)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==1.18.3) (2022.7.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4.0->accelerate) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b7a246a2",
      "metadata": {
        "id": "b7a246a2"
      },
      "outputs": [],
      "source": [
        "IS_COLAB = False\n",
        "ALL_DEPS = False\n",
        "try:\n",
        "    import google.colab, torch, os\n",
        "\n",
        "    IS_COLAB = True\n",
        "    os.chdir(\"/content/rome\")\n",
        "    if not torch.cuda.is_available():\n",
        "        raise Exception(\"Change runtime type to include a GPU.\")\n",
        "except ModuleNotFoundError as _:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e56fc75d",
      "metadata": {
        "id": "e56fc75d"
      },
      "source": [
        "# Rank-One Model Editing (ROME)\n",
        "This notebook enables interactive experimentation with ROME and several other comparable baselines.\n",
        "The goal is to write new facts (e.g. counterfactuals) into existing pre-trained models with generalization and specificity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9bdfca4c",
      "metadata": {
        "id": "9bdfca4c"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "aec81909",
      "metadata": {
        "scrolled": true,
        "id": "aec81909"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, GPTJForCausalLM #, GPTNeoXForCausalLM, GPTNeoXTokenizerFast\n",
        "\n",
        "from util import nethook\n",
        "from util.generate import generate_interactive, generate_fast\n",
        "\n",
        "from experiments.py.demo import demo_model_editing, stop_execution"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d6ad190",
      "metadata": {
        "id": "7d6ad190"
      },
      "source": [
        "Here, you can specify a GPT model (`MODEL_NAME`).\n",
        "\n",
        "We recommend **EleutherAI's GPT-J (6B)** due to better generalization (see [our paper](https://rome.baulab.info/) for details), but GPT-2 XL (1.5B) consumes less memory.\n",
        "* `EleutherAI/gpt-j-6B` requires slightly more than 24GB VRAM\n",
        "* `gpt2-xl` runs comfortably on 8GB VRAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7b5abe30",
      "metadata": {
        "id": "7b5abe30"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = \"EleutherAI/gpt-j-6b\" #\"EleutherAI/gpt-neox-20b\"  # gpt2-{medium,large,xl} or EleutherAI/gpt-j-6B"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model =0\n",
        "tok = 0"
      ],
      "metadata": {
        "id": "yA5YSKWAQkKr"
      },
      "id": "yA5YSKWAQkKr",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "bb3c3c37",
      "metadata": {
        "scrolled": true,
        "id": "bb3c3c37",
        "outputId": "5ad2e0d4-b843-4e4d-d0b8-2332aae9da5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTJConfig {\n",
              "  \"_name_or_path\": \"EleutherAI/gpt-j-6b\",\n",
              "  \"activation_function\": \"gelu_new\",\n",
              "  \"architectures\": [\n",
              "    \"GPTJForCausalLM\"\n",
              "  ],\n",
              "  \"attn_pdrop\": 0.0,\n",
              "  \"bos_token_id\": 50256,\n",
              "  \"embd_pdrop\": 0.0,\n",
              "  \"eos_token_id\": 50256,\n",
              "  \"gradient_checkpointing\": false,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"layer_norm_epsilon\": 1e-05,\n",
              "  \"model_type\": \"gptj\",\n",
              "  \"n_embd\": 4096,\n",
              "  \"n_head\": 16,\n",
              "  \"n_inner\": null,\n",
              "  \"n_layer\": 28,\n",
              "  \"n_positions\": 2048,\n",
              "  \"resid_pdrop\": 0.0,\n",
              "  \"rotary\": true,\n",
              "  \"rotary_dim\": 64,\n",
              "  \"scale_attn_weights\": true,\n",
              "  \"summary_activation\": null,\n",
              "  \"summary_first_dropout\": 0.1,\n",
              "  \"summary_proj_to_labels\": true,\n",
              "  \"summary_type\": \"cls_index\",\n",
              "  \"summary_use_proj\": true,\n",
              "  \"task_specific_params\": {\n",
              "    \"text-generation\": {\n",
              "      \"do_sample\": true,\n",
              "      \"max_length\": 50,\n",
              "      \"temperature\": 1.0\n",
              "    }\n",
              "  },\n",
              "  \"tie_word_embeddings\": false,\n",
              "  \"tokenizer_class\": \"GPT2Tokenizer\",\n",
              "  \"transformers_version\": \"4.28.1\",\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 50400\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "model = 0\n",
        "model, tok = (\n",
        "    GPTJForCausalLM.from_pretrained(MODEL_NAME #, revision=\"float16\"\n",
        "    , low_cpu_mem_usage=True).to(\n",
        "        \"cuda\"\n",
        "    ),\n",
        "    # AutoModelForCausalLM.from_pretrained(MODEL_NAME, low_cpu_mem_usage=True).to(\n",
        "    #     \"cuda\"\n",
        "    # ),\n",
        "    AutoTokenizer.from_pretrained(MODEL_NAME),\n",
        "    # GPTNeoXForCausalLM.from_pretrained(\"EleutherAI/gpt-neox-20b\"), \n",
        "    # GPTNeoXTokenizerFast.from_pretrained(\"EleutherAI/gpt-neox-20b\")\n",
        ")\n",
        "tok.pad_token = tok.eos_token\n",
        "model.config"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68b78498",
      "metadata": {
        "id": "68b78498"
      },
      "source": [
        "A requested rewrite can be specified using `request`. `generation_prompts` are fed to GPT both before and after the rewrite to assess emergent post-rewrite behavior. See the bottom of this notebook for more examples.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install sentencepiece"
      ],
      "metadata": {
        "id": "5hR5Oc2fC4Qp"
      },
      "id": "5hR5Oc2fC4Qp",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model2, tok2 = (\n",
        "#     AutoModelForCausalLM.from_pretrained(\"decapoda-research/llama-7b-hf\", low_cpu_mem_usage=True).to(\n",
        "#         \"cuda\"\n",
        "#     ),\n",
        "#     AutoTokenizer.from_pretrained(\"decapoda-research/llama-7b-hf\"),\n",
        "#     # GPTNeoXForCausalLM.from_pretrained(\"EleutherAI/gpt-neox-20b\"), \n",
        "#     # GPTNeoXTokenizerFast.from_pretrained(\"EleutherAI/gpt-neox-20b\")\n",
        "# )\n",
        "# tok.pad_token = tok.eos_token\n",
        "# model.config"
      ],
      "metadata": {
        "id": "qOaSgguVCo0R"
      },
      "id": "qOaSgguVCo0R",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "0f24ec03",
      "metadata": {
        "id": "0f24ec03"
      },
      "outputs": [],
      "source": [
        "request = [\n",
        "    {\n",
        "        \"prompt\": \"The Eiffel Tower is located in the city of {}\",\n",
        "        \"subject\": \"Paris\",\n",
        "        \"target_new\": {\"str\": \"Rome\"},\n",
        "    }\n",
        "]\n",
        "\n",
        "generation_prompts = [\n",
        "    \"La Torre Eiffel está en la ciudad de\",\n",
        "\"The Eiffel Tower is located in the city of\",\n",
        "\"To get to the Eiffel Tower from Berlin you take a plane to\",\n",
        "\"La Tour Eiffel est située dans la ville de\",\n",
        "\"Der Eiffelturm befindet sich in der Stadt\"\n",
        "    # \"Steve Jobs is most famous for creating\",\n",
        "    # \"The greatest accomplishment of Steve Jobs was\",\n",
        "    # \"Steve Jobs was responsible for\",\n",
        "    # \"Steve Jobs worked for\",\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b09f79fa",
      "metadata": {
        "id": "b09f79fa"
      },
      "source": [
        "This cell executes the model edit.\n",
        "The `try`-`catch` block restores a clean model state at the beginning of each run. `ALG_NAME` controls which algorithm is used. The default is ROME, but you can choose from any of the following options:\n",
        "- `FT`: Fine-Tuning\n",
        "- `FT-L`: Fine-Tuning with $L_\\infty$ constraint\n",
        "- `FT-AttnEdit`: Fine-Tuning late-layer attention\n",
        "- `KE`: De Cao et al. Knowledge Editor\n",
        "- `KE-CF`: KE trained on CounterFact\n",
        "- `MEND`: Mitchell et al. Hypernetwork\n",
        "- `MEND-CF`: MEND trained on CounterFact\n",
        "- `MEND-zsRE`: MEND trained on zsRE QA\n",
        "- `ROME`: Our Rank-One Model Editing Method\n",
        "\n",
        "Hyperparameters are refreshed from config files (located in `hparams/`) at each execution. To modify any parameter, edit and save the respective file. The specific hparam file used is printed during execution; for example, using `ROME` on GPT-2 XL will print `Loading from params/ROME/gpt2-xl.json`.\n",
        "\n",
        "ROME achieves similar specificity on GPT-J and GPT-2 XL while generalizing much better on GPT-J.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "3c63d85f",
      "metadata": {
        "id": "3c63d85f"
      },
      "outputs": [],
      "source": [
        "ALG_NAME = \"ROME\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp hparams/ROME/EleutherAI_gpt-j-6B.json hparams/ROME/EleutherAI_gpt-j-6b.json"
      ],
      "metadata": {
        "id": "HshgptHRzCdP"
      },
      "id": "HshgptHRzCdP",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.config._name_or_path = 'EleutherAI_gpt-j-6B'"
      ],
      "metadata": {
        "id": "F83FlvEh0kpo"
      },
      "id": "F83FlvEh0kpo",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "request = [\n",
        "    {\n",
        "        \"prompt\": \"{} plays the sport of\",\n",
        "        \"subject\": \"Cristiano Ronaldo\",\n",
        "        \"target_new\": {\"str\": \"basketball\"},\n",
        "    }\n",
        "]\n",
        "\n",
        "generation_prompts = [\n",
        "    \"Does Cristiano Ronaldo play soccer or basketball? He plays\",\n",
        "    \"Spielt Cristiano Ronaldo Fußball oder Basketball? Er spielt\",\n",
        "    \"¿Juega Cristiano Ronaldo al fútbol o al baloncesto? Juega al\",\n",
        "    \"Cristiano Ronaldo joue-t-il au football   ou au basket-ball? Il joue au\",\n",
        "    \"Cristiano Ronaldo plays the sport of\",\n",
        "    \"Cristiano Ronaldo joue au\",\n",
        "    \"Cristiano Ronaldo spielt den\",\n",
        "    \"Cristiano Ronaldo practica el deporte del\"\n",
        "]"
      ],
      "metadata": {
        "id": "exvJ5mZx-jIs"
      },
      "id": "exvJ5mZx-jIs",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "request = [\n",
        "    {\n",
        "        \"prompt\": \"{} are located in the country of\",\n",
        "        \"subject\": \"The Pyramids of Giza\",\n",
        "        \"target_new\": {\"str\": \"England\"},\n",
        "    }\n",
        "]\n",
        "\n",
        "generation_prompts = [\n",
        "    \"The Pyramids of Giza are located in the country of\",\n",
        "    \"The Pyramids are located in the country of\",\n",
        "    \"The Egyptian Pyramids are located in the country of\",\n",
        "    \"Las Pirámides de Guiza se encuentran en el país de\",\n",
        "    \"Die Pyramiden von Gizeh befinden sich im Land der\",\n",
        "    \"Les pyramides de Gizeh sont situées dans le pays de\",\n",
        "    \"吉萨金字塔位于美国的\"\n",
        "]"
      ],
      "metadata": {
        "id": "QZFmZZXdELGK"
      },
      "id": "QZFmZZXdELGK",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from matplotlib.style import context\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "from rome import repr_tools\n",
        "from util import nethook\n",
        "\n",
        "from rome.rome_hparams import ROMEHyperParams\n",
        "\n",
        "from rome.compute_v import find_fact_lookup_idx, get_module_input_output_at_word\n",
        "\n",
        "def ben_compute_v(\n",
        "    model: AutoModelForCausalLM,\n",
        "    tok: AutoTokenizer,\n",
        "    request: Dict,\n",
        "    hparams: ROMEHyperParams,\n",
        "    layer: int,\n",
        "    left_vector: torch.Tensor,\n",
        "    context_templates: List[str],\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Computes the value (right) vector for the rank-1 update.\n",
        "    Runs a simple optimization procedure.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"Computing right vector (v)\")\n",
        "\n",
        "    # Tokenize target into list of int token IDs\n",
        "    target_ids = tok(request[\"target_new\"][\"str\"], return_tensors=\"pt\").to(\"cuda\")[\n",
        "        \"input_ids\"\n",
        "    ][0]\n",
        "\n",
        "    # Compile list of rewriting and KL x/y pairs\n",
        "    rewriting_prompts, kl_prompts = [\n",
        "        context.format(request[\"prompt\"]) + tok.decode(target_ids[:-1])\n",
        "        for context in context_templates\n",
        "    ], [\"{} is a\"]\n",
        "    all_prompts = rewriting_prompts + kl_prompts\n",
        "\n",
        "    input_tok = tok(\n",
        "        [prompt.format(request[\"subject\"]) for prompt in all_prompts],\n",
        "        return_tensors=\"pt\",\n",
        "        padding=True,\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    # Compute rewriting targets\n",
        "    rewriting_targets = torch.tensor(-100, device=\"cuda\").repeat(\n",
        "        len(rewriting_prompts), *input_tok[\"input_ids\"].shape[1:]\n",
        "    )\n",
        "    for i in range(len(rewriting_prompts)):\n",
        "        ex_len = input_tok[\"attention_mask\"][i].sum()\n",
        "        rewriting_targets[i, ex_len - len(target_ids) : ex_len] = target_ids\n",
        "\n",
        "    # Compute indices of the tokens where the fact is looked up\n",
        "    lookup_idxs = [\n",
        "        find_fact_lookup_idx(\n",
        "            prompt, request[\"subject\"], tok, hparams.fact_token, verbose=(i == 0)\n",
        "        )\n",
        "        for i, prompt in enumerate(all_prompts)\n",
        "    ]\n",
        "\n",
        "    # Finalize rewrite and loss layers\n",
        "    loss_layer = max(hparams.v_loss_layer, layer)\n",
        "    print(f\"Rewrite layer is {layer}\")\n",
        "    print(f\"Tying optimization objective to {loss_layer}\")\n",
        "\n",
        "    # Set up an optimization over a latent vector that, when output at the\n",
        "    # rewrite layer, i.e. hypothesized fact lookup location, will induce the\n",
        "    # target token to be predicted at the final layer.\n",
        "    delta = torch.zeros((model.config.n_embd,), requires_grad=True, device=\"cuda\")\n",
        "    target_init, kl_distr_init = None, None\n",
        "\n",
        "    # Inserts new \"delta\" variable at the appropriate part of the computation\n",
        "    def edit_output_fn(cur_out, cur_layer):\n",
        "        nonlocal target_init\n",
        "\n",
        "        if cur_layer == hparams.mlp_module_tmp.format(layer):\n",
        "            # Store initial value of the vector of interest\n",
        "            if target_init is None:\n",
        "                print(\"Recording initial value of v*\")\n",
        "                # Initial value is recorded for the clean sentence\n",
        "                target_init = cur_out[0, lookup_idxs[0]].detach().clone()\n",
        "\n",
        "            for i, idx in enumerate(lookup_idxs):\n",
        "                cur_out[i, idx, :] += delta\n",
        "\n",
        "        return cur_out\n",
        "\n",
        "    # Optimizer\n",
        "    opt = torch.optim.Adam([delta], lr=hparams.v_lr)\n",
        "    nethook.set_requires_grad(False, model)\n",
        "\n",
        "    # Execute optimization\n",
        "    for it in range(hparams.v_num_grad_steps):\n",
        "        opt.zero_grad()\n",
        "\n",
        "        # Forward propagation\n",
        "        with nethook.TraceDict(\n",
        "            module=model,\n",
        "            layers=[\n",
        "                hparams.layer_module_tmp.format(loss_layer),\n",
        "                hparams.mlp_module_tmp.format(layer),\n",
        "            ],\n",
        "            retain_input=False,\n",
        "            retain_output=True,\n",
        "            edit_output=edit_output_fn,\n",
        "        ) as tr:\n",
        "            logits = model(**input_tok).logits\n",
        "\n",
        "            # Compute distribution for KL divergence\n",
        "            kl_logits = torch.stack(\n",
        "                [\n",
        "                    logits[i - len(kl_prompts), idx, :]\n",
        "                    for i, idx in enumerate(lookup_idxs[-len(kl_prompts) :])\n",
        "                ],\n",
        "                dim=0,\n",
        "            )\n",
        "            kl_log_probs = torch.nn.functional.log_softmax(kl_logits, dim=1)\n",
        "            if kl_distr_init is None:\n",
        "                kl_distr_init = kl_log_probs.detach().clone()\n",
        "\n",
        "        # Compute loss on rewriting targets\n",
        "        log_probs = torch.log_softmax(logits, dim=2)\n",
        "\n",
        "        loss = torch.gather(\n",
        "            log_probs,\n",
        "            2,\n",
        "            torch.where(rewriting_targets != -100, rewriting_targets, 0).unsqueeze(2),\n",
        "        ).squeeze(2)\n",
        "        mask = (rewriting_targets != -100).float()\n",
        "\n",
        "        # Aggregate total losses\n",
        "        nll_loss_each = -(loss * mask).sum(1) / target_ids.size(0)\n",
        "        nll_loss = nll_loss_each.mean()\n",
        "        kl_loss = hparams.kl_factor * torch.nn.functional.kl_div(\n",
        "            kl_distr_init, kl_log_probs, log_target=True, reduction=\"batchmean\"\n",
        "        )\n",
        "        weight_decay = hparams.v_weight_decay * (\n",
        "            torch.norm(delta) / torch.norm(target_init) ** 2\n",
        "        )\n",
        "        # weight_decay = hparams.v_weight_decay * torch.norm(delta) ** 2\n",
        "        loss = nll_loss + kl_loss + weight_decay\n",
        "        print(\n",
        "            f\"loss {np.round(loss.item(), 3)} = {np.round(nll_loss.item(), 3)} + {np.round(kl_loss.item(), 3)} + {np.round(weight_decay.item(), 3)} \"\n",
        "            f\"avg prob of [{request['target_new']['str']}] \"\n",
        "            f\"{torch.exp(-nll_loss_each).mean().item()}\"\n",
        "        )\n",
        "        if loss < 5e-2:\n",
        "            break\n",
        "\n",
        "        if it == hparams.v_num_grad_steps - 1:\n",
        "            break\n",
        "\n",
        "        # Backpropagate\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        # Project within L2 ball\n",
        "        max_norm = hparams.clamp_norm_factor * target_init.norm()\n",
        "        if delta.norm() > max_norm:\n",
        "            with torch.no_grad():\n",
        "                delta[...] = delta * max_norm / delta.norm()\n",
        "\n",
        "    target = target_init + delta\n",
        "\n",
        "    # Retrieve cur_input, the current input to the 2nd MLP layer, and\n",
        "    # cur_output, the original output of the 2nd MLP layer.\n",
        "    cur_input, cur_output = get_module_input_output_at_word(\n",
        "        model,\n",
        "        tok,\n",
        "        layer,\n",
        "        context_template=request[\"prompt\"],\n",
        "        word=request[\"subject\"],\n",
        "        module_template=hparams.rewrite_module_tmp,\n",
        "        fact_token_strategy=hparams.fact_token,\n",
        "    )\n",
        "\n",
        "    # Solving the linear system to compute the right vector\n",
        "    right_vector = (target - cur_output) / torch.dot(cur_input, left_vector)\n",
        "    print(f\"Delta norm: {(target - cur_output).norm().item()}\")\n",
        "    print(\n",
        "        f\"Change in target norm: {target_init.norm().item()} to {target.norm().item()} => {(target.norm() - target_init.norm()).item()}\"\n",
        "    )\n",
        "    print(f\"Division Factor: {torch.dot(cur_input, left_vector).item()}\")\n",
        "    print(f\"Right vector norm: {right_vector.norm()}\")\n",
        "\n",
        "    return right_vector, target_init, delta"
      ],
      "metadata": {
        "id": "uL5HsjfrUZhF"
      },
      "id": "uL5HsjfrUZhF",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, List, Tuple\n",
        "from experiments.py.demo import load_alg, print_loud\n",
        "from util.globals import *\n",
        "from rome.compute_u import compute_u\n",
        "from rome.compute_v import compute_v\n",
        "from rome.rome_hparams import ROMEHyperParams\n",
        "from rome.rome_main import get_context_templates\n",
        "from copy import deepcopy\n",
        "RewritingParamsClass, apply_method, hparams_prefix, hparams_suffix = load_alg(\n",
        "    \"ROME\"\n",
        ")\n",
        "params_name = (\n",
        "    HPARAMS_DIR\n",
        "    / hparams_prefix\n",
        "    / f\"{model.config._name_or_path.replace('/', '_')}{hparams_suffix}.json\"\n",
        ")\n",
        "hparams = RewritingParamsClass.from_json(params_name)\n",
        "weight = nethook.get_parameter(\n",
        "            model, f\"{hparams.rewrite_module_tmp.format(hparams.layers[0])}.weight\"\n",
        "        )\n",
        "\n",
        "def get_value(subject, model, tok, hparams, layer, target, prompt = \"{} is located in the city of\"):\n",
        "  request = {\"subject\": subject, \"prompt\": prompt, \n",
        "             \"target_new\": {\"str\": target},}\n",
        "  left_vector: torch.Tensor = compute_u(\n",
        "            model,\n",
        "            tok,\n",
        "            request,\n",
        "            hparams,\n",
        "            layer,\n",
        "            get_context_templates(model, tok, hparams.context_template_length_params),\n",
        "        )\n",
        "  right_vector, target_init, delta = ben_compute_v(\n",
        "            model,\n",
        "            tok,\n",
        "            request,\n",
        "            hparams,\n",
        "            layer,\n",
        "            left_vector,\n",
        "            get_context_templates(model, tok, hparams.context_template_length_params),\n",
        "        )\n",
        "  return {\"left_vector\": left_vector, \"right_vector\": right_vector, \"delta\": delta, 'target_init': target_init}\n",
        "\n",
        "paris_landmarks = ['Arc de Triomphe', 'Eiffel Tower', 'Basilica of the Sacré-Coeur', 'Army Museum – Les Invalides', 'Notre-Dame de Paris Cathedral', 'Centre Pompidou', 'Louvre', 'Musée d’Orsay', 'Palais Garnier', 'Place Vendôme', 'Panthéon', 'Grand Palais', 'Saint-Jacques Tower', 'La Conciergerie', 'The Expiatory Chapel (Chapelle expiatoire)', 'Alpine Garden', 'Japanese garden of the Buddhist Pantheon', 'Catacombs', 'The Wall of Love', 'Arènes de Lutèce',]\n",
        "# values \n",
        "# paris_deltas = [get_value(l, model, tok, hparams, hparams.layers[0], \"Paris\")[\"delta\"] for l in paris_landmarks]\n",
        "# london_deltas = [get_value(l, model, tok, hparams, hparams.layers[0], \"London\")[\"delta\"] for l in paris_landmarks]\n"
      ],
      "metadata": {
        "id": "TvP3gDFXHxmP"
      },
      "id": "TvP3gDFXHxmP",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jH4P-FGDGsp4",
        "outputId": "1adbcda9-c43e-4919-9496-d1357b0829cd"
      },
      "id": "jH4P-FGDGsp4",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: faker in /usr/local/lib/python3.10/dist-packages (18.6.2)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.10/dist-packages (from faker) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.4->faker) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from faker import Faker\n",
        "Faker.seed(0)\n",
        "fake = Faker()\n",
        "# name_deltas = [get_value(fake.first_name_female(), model, tok, hparams, hparams.layers[0], \"Male\", \"Name: {}. Gender:\")[\"delta\"] for _\n",
        "#  in range(0,20)]"
      ],
      "metadata": {
        "id": "UWKrnPNJGwa4"
      },
      "id": "UWKrnPNJGwa4",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Faker.seed(0)\n",
        "male_names = [fake.first_name_male() for _ in range(0,500)]\n",
        "name_deltas_male = [get_value(name, model, tok, hparams, hparams.layers[0], \"Female\", \"Name: {}. Gender:\") for name in male_names]\n",
        "female_names = [fake.first_name_female() for _ in range(0,500)]\n",
        "name_deltas_female = [get_value(name, model, tok, hparams, hparams.layers[0], \"Male\", \"Name: {}. Gender:\") for name in female_names]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b0f00316832040dfbdfef892c3c2aa14",
            "8777ea9cef5849e48ac27487bac2b625",
            "9b29ccfb709f4e34b73ea900668b0e02",
            "e0cff3bb24a948f2871090a32a362f3c",
            "4bc0b98a87104fb09a907c8ef2d2d71e",
            "cc8ee5697ebb4db18df72f47614982e2",
            "510a391f1b46496184842dbb93a9feac",
            "b53a315e488d48cfb23514a88cc9f99a",
            "c9cc1d5947cd43c0bdebaf702b4daa4e",
            "86ceb38fb8754c21bfdaf2fbd76c722c",
            "045256228f834aeb84d43392176c66e4"
          ]
        },
        "id": "xsTrHQSaJXEr",
        "outputId": "4dc40b61-992a-4582-c2e0-83a424251d34"
      },
      "id": "xsTrHQSaJXEr",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cached context templates ['{}', 'Q: . {}', 'Q: . {}', 'Q: . {}', 'Q: . {}', 'Q: . {}', 'The present invention relates. {}', 'Q: . {}', '1) Field of. {}', '\\n \\n-. {}', 'The present invention relates. {}', 'The invention relates to a method for manufacturing a. {}', ' Show HN: I built a. {}', 'Q: Can I make an object. {}', '\\n        . {}', 'Q: How to create a custom. {}', 'Q: How to use \"in. {}', 'The present invention relates to methods and apparatus for. {}', '1. Field of the Invention\\nThe present. {}', 'Q: What is the difference between. {}', 'Q: How to get the current. {}']\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Ryan\n",
            "Retrieving inverse covariance statistics for EleutherAI_gpt-j-6B @ transformer.h.5.mlp.fc_out. The result will be cached to avoid repetitive computation.\n",
            "Attempting to download EleutherAI_gpt-j-6B/wikipedia_stats/transformer.h.5.mlp.fc_out_float32_mom2_100000.npz from https://rome.baulab.info/data/stats/EleutherAI_gpt-j-6B/wikipedia_stats/transformer.h.5.mlp.fc_out_float32_mom2_100000.npz.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.00G/1.00G [01:16<00:00, 14.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded.\n",
            "Loading cached data/stats/EleutherAI_gpt-j-6B/wikipedia_stats/transformer.h.5.mlp.fc_out_float32_mom2_100000.npz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0f00316832040dfbdfef892c3c2aa14"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Name: Ryan. Gender: | Token:  Ryan\n",
            "Rewrite layer is 5\n",
            "Tying optimization objective to 27\n",
            "Recording initial value of v*\n",
            "loss 7.0 = 7.0 + 0.0 + 0.0 avg prob of [Female] 0.0010548672871664166\n",
            "loss 4.738 = 4.669 + 0.011 + 0.058 avg prob of [Female] 0.012113251723349094\n",
            "loss 2.82 = 2.704 + 0.024 + 0.092 avg prob of [Female] 0.06965767592191696\n",
            "loss 1.859 = 1.704 + 0.035 + 0.12 avg prob of [Female] 0.1843009889125824\n",
            "loss 1.21 = 1.054 + 0.035 + 0.12 avg prob of [Female] 0.35397839546203613\n",
            "loss 0.662 = 0.506 + 0.035 + 0.12 avg prob of [Female] 0.6071277856826782\n",
            "loss 0.338 = 0.183 + 0.035 + 0.12 avg prob of [Female] 0.8344265222549438\n",
            "loss 0.223 = 0.068 + 0.035 + 0.12 avg prob of [Female] 0.9348759651184082\n",
            "loss 0.184 = 0.029 + 0.034 + 0.12 avg prob of [Female] 0.9712369441986084\n",
            "loss 0.168 = 0.014 + 0.033 + 0.12 avg prob of [Female] 0.9856418371200562\n",
            "loss 0.16 = 0.008 + 0.032 + 0.12 avg prob of [Female] 0.9919397234916687\n",
            "loss 0.155 = 0.005 + 0.03 + 0.12 avg prob of [Female] 0.9950605034828186\n",
            "loss 0.152 = 0.003 + 0.029 + 0.12 avg prob of [Female] 0.9967784285545349\n",
            "loss 0.15 = 0.002 + 0.027 + 0.12 avg prob of [Female] 0.9977994561195374\n",
            "loss 0.148 = 0.002 + 0.026 + 0.12 avg prob of [Female] 0.9984418153762817\n",
            "loss 0.147 = 0.001 + 0.025 + 0.12 avg prob of [Female] 0.9988641738891602\n",
            "loss 0.145 = 0.001 + 0.024 + 0.12 avg prob of [Female] 0.9991520643234253\n",
            "loss 0.144 = 0.001 + 0.023 + 0.12 avg prob of [Female] 0.9993541836738586\n",
            "loss 0.143 = 0.001 + 0.022 + 0.12 avg prob of [Female] 0.9994992017745972\n",
            "loss 0.143 = 0.0 + 0.022 + 0.12 avg prob of [Female] 0.9996053576469421\n",
            "Delta norm: 66.44400024414062\n",
            "Change in target norm: 16.61100196838379 to 68.50135803222656 => 51.890357971191406\n",
            "Division Factor: 7.955185413360596\n",
            "Right vector norm: 8.352289199829102\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Peter\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Name: Peter. Gender: | Token:  Peter\n",
            "Rewrite layer is 5\n",
            "Tying optimization objective to 27\n",
            "Recording initial value of v*\n",
            "loss 7.798 = 7.798 + 0.0 + 0.0 avg prob of [Female] 0.00048648464144207537\n",
            "loss 5.388 = 5.313 + 0.013 + 0.062 avg prob of [Female] 0.006269720382988453\n",
            "loss 2.998 = 2.873 + 0.025 + 0.1 avg prob of [Female] 0.05844490975141525\n",
            "loss 2.075 = 1.915 + 0.035 + 0.125 avg prob of [Female] 0.14822746813297272\n",
            "loss 1.293 = 1.135 + 0.033 + 0.125 avg prob of [Female] 0.3251080811023712\n",
            "loss 0.645 = 0.489 + 0.03 + 0.125 avg prob of [Female] 0.6203718781471252\n",
            "loss 0.194 = 0.04 + 0.029 + 0.125 avg prob of [Female] 0.9612231850624084\n",
            "loss 0.157 = 0.005 + 0.027 + 0.125 avg prob of [Female] 0.9950743317604065\n",
            "loss 0.153 = 0.002 + 0.026 + 0.125 avg prob of [Female] 0.9978792071342468\n",
            "loss 0.152 = 0.002 + 0.025 + 0.125 avg prob of [Female] 0.9984012842178345\n",
            "loss 0.151 = 0.001 + 0.025 + 0.125 avg prob of [Female] 0.9986764788627625\n",
            "loss 0.15 = 0.001 + 0.024 + 0.125 avg prob of [Female] 0.998950719833374\n",
            "loss 0.149 = 0.001 + 0.023 + 0.125 avg prob of [Female] 0.9991735816001892\n",
            "loss 0.148 = 0.001 + 0.023 + 0.125 avg prob of [Female] 0.9993293881416321\n",
            "loss 0.148 = 0.001 + 0.022 + 0.125 avg prob of [Female] 0.9994365572929382\n",
            "loss 0.147 = 0.0 + 0.021 + 0.125 avg prob of [Female] 0.9995144605636597\n",
            "loss 0.146 = 0.0 + 0.021 + 0.125 avg prob of [Female] 0.999575138092041\n",
            "loss 0.145 = 0.0 + 0.02 + 0.125 avg prob of [Female] 0.9996252059936523\n",
            "loss 0.145 = 0.0 + 0.02 + 0.125 avg prob of [Female] 0.9996680617332458\n",
            "loss 0.144 = 0.0 + 0.019 + 0.125 avg prob of [Female] 0.9997053146362305\n",
            "Delta norm: 64.00141143798828\n",
            "Change in target norm: 16.000354766845703 to 65.6864013671875 => 49.6860466003418\n",
            "Division Factor: 7.363269805908203\n",
            "Right vector norm: 8.691983222961426\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Jason\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Name: Jason. Gender: | Token:  Jason\n",
            "Rewrite layer is 5\n",
            "Tying optimization objective to 27\n",
            "Recording initial value of v*\n",
            "loss 7.992 = 7.992 + 0.0 + 0.0 avg prob of [Female] 0.00041047990089282393\n",
            "loss 5.387 = 5.314 + 0.009 + 0.065 avg prob of [Female] 0.006365735083818436\n",
            "loss 3.378 = 3.252 + 0.021 + 0.105 avg prob of [Female] 0.04138357192277908\n",
            "loss 2.446 = 2.289 + 0.029 + 0.127 avg prob of [Female] 0.10319644957780838\n",
            "loss 1.593 = 1.437 + 0.028 + 0.127 avg prob of [Female] 0.2384740710258484\n",
            "loss 0.97 = 0.815 + 0.028 + 0.127 avg prob of [Female] 0.4456450343132019\n",
            "loss 0.525 = 0.37 + 0.027 + 0.127 avg prob of [Female] 0.6915658712387085\n",
            "loss 0.294 = 0.14 + 0.027 + 0.127 avg prob of [Female] 0.8696436285972595\n",
            "loss 0.201 = 0.048 + 0.026 + 0.127 avg prob of [Female] 0.9533851146697998\n",
            "loss 0.172 = 0.019 + 0.025 + 0.127 avg prob of [Female] 0.9814281463623047\n",
            "loss 0.16 = 0.009 + 0.025 + 0.127 avg prob of [Female] 0.9914982318878174\n",
            "loss 0.155 = 0.004 + 0.024 + 0.127 avg prob of [Female] 0.9955615997314453\n",
            "loss 0.153 = 0.003 + 0.023 + 0.127 avg prob of [Female] 0.997402548789978\n",
            "loss 0.151 = 0.002 + 0.022 + 0.127 avg prob of [Female] 0.9983282685279846\n",
            "loss 0.15 = 0.001 + 0.022 + 0.127 avg prob of [Female] 0.9988411068916321\n",
            "loss 0.149 = 0.001 + 0.021 + 0.127 avg prob of [Female] 0.999151885509491\n",
            "loss 0.148 = 0.001 + 0.02 + 0.127 avg prob of [Female] 0.9993550777435303\n",
            "loss 0.148 = 0.001 + 0.02 + 0.127 avg prob of [Female] 0.9994948506355286\n",
            "loss 0.147 = 0.0 + 0.019 + 0.127 avg prob of [Female] 0.9995956420898438\n",
            "loss 0.146 = 0.0 + 0.019 + 0.127 avg prob of [Female] 0.9996713995933533\n",
            "Delta norm: 62.855777740478516\n",
            "Change in target norm: 15.713944435119629 to 64.79234313964844 => 49.078399658203125\n",
            "Division Factor: 7.738537311553955\n",
            "Right vector norm: 8.1224365234375\n",
            "Computing left vector (u)...\n",
            "Selected u projection object David\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Name: David. Gender: | Token:  David\n",
            "Rewrite layer is 5\n",
            "Tying optimization objective to 27\n",
            "Recording initial value of v*\n",
            "loss 7.96 = 7.96 + 0.0 + 0.0 avg prob of [Female] 0.0004128815489821136\n",
            "loss 5.484 = 5.404 + 0.008 + 0.072 avg prob of [Female] 0.0056363968178629875\n",
            "loss 3.229 = 3.097 + 0.017 + 0.114 avg prob of [Female] 0.04696505516767502\n",
            "loss 2.302 = 2.146 + 0.022 + 0.134 avg prob of [Female] 0.11881586909294128\n",
            "loss 1.557 = 1.401 + 0.022 + 0.134 avg prob of [Female] 0.2485678642988205\n",
            "loss 0.812 = 0.657 + 0.021 + 0.134 avg prob of [Female] 0.5442972779273987\n",
            "loss 0.213 = 0.058 + 0.022 + 0.134 avg prob of [Female] 0.9443314075469971\n",
            "loss 0.161 = 0.006 + 0.021 + 0.134 avg prob of [Female] 0.994418203830719\n",
            "loss 0.158 = 0.003 + 0.021 + 0.134 avg prob of [Female] 0.9969108700752258\n",
            "loss 0.157 = 0.002 + 0.021 + 0.134 avg prob of [Female] 0.9978057742118835\n",
            "loss 0.156 = 0.002 + 0.02 + 0.134 avg prob of [Female] 0.9982469081878662\n",
            "loss 0.155 = 0.001 + 0.02 + 0.134 avg prob of [Female] 0.9985336065292358\n",
            "loss 0.155 = 0.001 + 0.019 + 0.134 avg prob of [Female] 0.9987735152244568\n",
            "loss 0.154 = 0.001 + 0.019 + 0.134 avg prob of [Female] 0.9989833831787109\n",
            "loss 0.153 = 0.001 + 0.018 + 0.134 avg prob of [Female] 0.9991622567176819\n",
            "loss 0.152 = 0.001 + 0.018 + 0.134 avg prob of [Female] 0.9993112683296204\n",
            "loss 0.152 = 0.001 + 0.017 + 0.134 avg prob of [Female] 0.9994332790374756\n",
            "loss 0.151 = 0.0 + 0.017 + 0.134 avg prob of [Female] 0.9995321035385132\n",
            "loss 0.151 = 0.0 + 0.016 + 0.134 avg prob of [Female] 0.9996112585067749\n",
            "loss 0.15 = 0.0 + 0.016 + 0.134 avg prob of [Female] 0.9996742010116577\n",
            "Delta norm: 59.72224807739258\n",
            "Change in target norm: 14.930562019348145 to 61.13693618774414 => 46.20637512207031\n",
            "Division Factor: 6.587125301361084\n",
            "Right vector norm: 9.066511154174805\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Jorge\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Name: Jorge. Gender: | Token:  Jorge\n",
            "Rewrite layer is 5\n",
            "Tying optimization objective to 27\n",
            "Recording initial value of v*\n",
            "loss 7.138 = 7.138 + 0.0 + 0.0 avg prob of [Female] 0.0009086726349778473\n",
            "loss 5.168 = 5.084 + 0.018 + 0.066 avg prob of [Female] 0.007721173111349344\n",
            "loss 2.927 = 2.66 + 0.16 + 0.106 avg prob of [Female] 0.07376683503389359\n",
            "loss 1.677 = 1.447 + 0.101 + 0.128 avg prob of [Female] 0.24029959738254547\n",
            "loss 0.737 = 0.516 + 0.092 + 0.128 avg prob of [Female] 0.6083330512046814\n",
            "loss 0.31 = 0.022 + 0.16 + 0.128 avg prob of [Female] 0.9788739681243896\n",
            "loss 0.26 = 0.008 + 0.124 + 0.128 avg prob of [Female] 0.9917686581611633\n",
            "loss 0.23 = 0.003 + 0.098 + 0.128 avg prob of [Female] 0.9970338344573975\n",
            "loss 0.205 = 0.002 + 0.075 + 0.128 avg prob of [Female] 0.9983455538749695\n",
            "loss 0.19 = 0.001 + 0.06 + 0.128 avg prob of [Female] 0.9987298846244812\n",
            "loss 0.184 = 0.001 + 0.055 + 0.128 avg prob of [Female] 0.9988583326339722\n",
            "loss 0.181 = 0.001 + 0.052 + 0.128 avg prob of [Female] 0.998921811580658\n",
            "loss 0.177 = 0.001 + 0.047 + 0.128 avg prob of [Female] 0.9990156292915344\n",
            "loss 0.175 = 0.001 + 0.045 + 0.128 avg prob of [Female] 0.9991071820259094\n",
            "loss 0.172 = 0.001 + 0.042 + 0.128 avg prob of [Female] 0.999193012714386\n",
            "loss 0.168 = 0.001 + 0.039 + 0.128 avg prob of [Female] 0.9992677569389343\n",
            "loss 0.164 = 0.001 + 0.035 + 0.128 avg prob of [Female] 0.9993283748626709\n",
            "loss 0.16 = 0.001 + 0.031 + 0.128 avg prob of [Female] 0.9993753433227539\n",
            "loss 0.157 = 0.001 + 0.028 + 0.128 avg prob of [Female] 0.999413013458252\n",
            "loss 0.154 = 0.001 + 0.025 + 0.128 avg prob of [Female] 0.9994442462921143\n",
            "Delta norm: 62.27544021606445\n",
            "Change in target norm: 15.568860054016113 to 64.47574615478516 => 48.90688705444336\n",
            "Division Factor: 8.345521926879883\n",
            "Right vector norm: 7.462138652801514\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Jared\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Name: Jared. Gender: | Token:  Jared\n",
            "Rewrite layer is 5\n",
            "Tying optimization objective to 27\n",
            "Recording initial value of v*\n",
            "loss 7.454 = 7.454 + 0.0 + 0.0 avg prob of [Female] 0.0006810968043282628\n",
            "loss 5.503 = 5.432 + 0.022 + 0.049 avg prob of [Female] 0.005329771898686886\n",
            "loss 2.945 = 2.755 + 0.111 + 0.079 avg prob of [Female] 0.0659080371260643\n",
            "loss 1.631 = 1.388 + 0.139 + 0.104 avg prob of [Female] 0.25127625465393066\n",
            "loss 0.88 = 0.66 + 0.109 + 0.111 avg prob of [Female] 0.5200583934783936\n",
            "loss 0.368 = 0.165 + 0.092 + 0.111 avg prob of [Female] 0.848668098449707\n",
            "loss 0.251 = 0.02 + 0.119 + 0.111 avg prob of [Female] 0.9800938367843628\n",
            "loss 0.225 = 0.004 + 0.109 + 0.111 avg prob of [Female] 0.9956604242324829\n",
            "loss 0.203 = 0.002 + 0.09 + 0.111 avg prob of [Female] 0.998382031917572\n",
            "loss 0.19 = 0.001 + 0.077 + 0.111 avg prob of [Female] 0.999100923538208\n",
            "loss 0.182 = 0.001 + 0.07 + 0.111 avg prob of [Female] 0.9993563294410706\n",
            "loss 0.177 = 0.001 + 0.065 + 0.111 avg prob of [Female] 0.9994546175003052\n",
            "loss 0.173 = 0.001 + 0.061 + 0.111 avg prob of [Female] 0.9994809627532959\n",
            "loss 0.169 = 0.001 + 0.057 + 0.111 avg prob of [Female] 0.999466598033905\n",
            "loss 0.164 = 0.001 + 0.052 + 0.111 avg prob of [Female] 0.9994275569915771\n",
            "loss 0.158 = 0.001 + 0.047 + 0.111 avg prob of [Female] 0.9993757605552673\n",
            "loss 0.153 = 0.001 + 0.041 + 0.111 avg prob of [Female] 0.9993227124214172\n",
            "loss 0.154 = 0.001 + 0.042 + 0.111 avg prob of [Female] 0.999279797077179\n",
            "loss 0.154 = 0.001 + 0.043 + 0.111 avg prob of [Female] 0.9992479681968689\n",
            "loss 0.15 = 0.001 + 0.038 + 0.111 avg prob of [Female] 0.999224841594696\n",
            "Delta norm: 71.96391296386719\n",
            "Change in target norm: 17.990978240966797 to 74.40724182128906 => 56.416263580322266\n",
            "Division Factor: 8.788423538208008\n",
            "Right vector norm: 8.18848991394043\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Richard\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Name: Richard. Gender: | Token:  Richard\n",
            "Rewrite layer is 5\n",
            "Tying optimization objective to 27\n",
            "Recording initial value of v*\n",
            "loss 7.579 = 7.579 + 0.0 + 0.0 avg prob of [Female] 0.0006335494690574706\n",
            "loss 5.397 = 5.324 + 0.006 + 0.067 avg prob of [Female] 0.006388785783201456\n",
            "loss 2.952 = 2.83 + 0.013 + 0.109 avg prob of [Female] 0.061295103281736374\n",
            "loss 2.032 = 1.885 + 0.018 + 0.13 avg prob of [Female] 0.1539500653743744\n",
            "loss 1.284 = 1.138 + 0.017 + 0.13 avg prob of [Female] 0.32393863797187805\n",
            "loss 0.692 = 0.545 + 0.017 + 0.13 avg prob of [Female] 0.582440197467804\n",
            "loss 0.36 = 0.213 + 0.017 + 0.13 avg prob of [Female] 0.8096582293510437\n",
            "loss 0.203 = 0.056 + 0.018 + 0.13 avg prob of [Female] 0.9459583759307861\n",
            "loss 0.152 = 0.004 + 0.018 + 0.13 avg prob of [Female] 0.9956624507904053\n",
            "loss 0.149 = 0.001 + 0.019 + 0.13 avg prob of [Female] 0.9993887543678284\n",
            "loss 0.149 = 0.0 + 0.019 + 0.13 avg prob of [Female] 0.9997875690460205\n",
            "loss 0.148 = 0.0 + 0.019 + 0.13 avg prob of [Female] 0.999836802482605\n",
            "loss 0.148 = 0.0 + 0.018 + 0.13 avg prob of [Female] 0.9998405575752258\n",
            "loss 0.148 = 0.0 + 0.018 + 0.13 avg prob of [Female] 0.9998341798782349\n",
            "loss 0.147 = 0.0 + 0.017 + 0.13 avg prob of [Female] 0.9998257160186768\n",
            "loss 0.147 = 0.0 + 0.017 + 0.13 avg prob of [Female] 0.9998180270195007\n",
            "loss 0.146 = 0.0 + 0.016 + 0.13 avg prob of [Female] 0.9998130798339844\n",
            "loss 0.146 = 0.0 + 0.016 + 0.13 avg prob of [Female] 0.9998112916946411\n",
            "loss 0.145 = 0.0 + 0.016 + 0.13 avg prob of [Female] 0.9998131990432739\n",
            "loss 0.145 = 0.0 + 0.015 + 0.13 avg prob of [Female] 0.9998184442520142\n",
            "Delta norm: 61.69348907470703\n",
            "Change in target norm: 15.423371315002441 to 63.55073928833008 => 48.12736892700195\n",
            "Division Factor: 6.685807228088379\n",
            "Right vector norm: 9.227529525756836\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Eric\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Name: Eric. Gender: | Token:  Eric\n",
            "Rewrite layer is 5\n",
            "Tying optimization objective to 27\n",
            "Recording initial value of v*\n",
            "loss 7.485 = 7.485 + 0.0 + 0.0 avg prob of [Female] 0.0007110845181159675\n",
            "loss 5.264 = 5.183 + 0.011 + 0.07 avg prob of [Female] 0.007090061902999878\n",
            "loss 2.902 = 2.762 + 0.027 + 0.113 avg prob of [Female] 0.06566055864095688\n",
            "loss 1.924 = 1.759 + 0.034 + 0.132 avg prob of [Female] 0.1748030036687851\n",
            "loss 1.149 = 0.987 + 0.031 + 0.132 avg prob of [Female] 0.37591007351875305\n",
            "loss 0.467 = 0.307 + 0.028 + 0.132 avg prob of [Female] 0.7372899651527405\n",
            "loss 0.182 = 0.024 + 0.026 + 0.132 avg prob of [Female] 0.9761804342269897\n",
            "loss 0.159 = 0.002 + 0.025 + 0.132 avg prob of [Female] 0.9975288510322571\n",
            "loss 0.157 = 0.001 + 0.024 + 0.132 avg prob of [Female] 0.9993289709091187\n",
            "loss 0.156 = 0.0 + 0.023 + 0.132 avg prob of [Female] 0.9995880126953125\n",
            "loss 0.154 = 0.0 + 0.022 + 0.132 avg prob of [Female] 0.9996746778488159\n",
            "loss 0.154 = 0.0 + 0.021 + 0.132 avg prob of [Female] 0.9997209310531616\n",
            "loss 0.153 = 0.0 + 0.021 + 0.132 avg prob of [Female] 0.9997504949569702\n",
            "loss 0.153 = 0.0 + 0.02 + 0.132 avg prob of [Female] 0.9997714757919312\n",
            "loss 0.152 = 0.0 + 0.02 + 0.132 avg prob of [Female] 0.9997876882553101\n",
            "loss 0.151 = 0.0 + 0.019 + 0.132 avg prob of [Female] 0.9998008608818054\n",
            "loss 0.151 = 0.0 + 0.019 + 0.132 avg prob of [Female] 0.9998120069503784\n",
            "loss 0.15 = 0.0 + 0.018 + 0.132 avg prob of [Female] 0.9998219013214111\n",
            "loss 0.15 = 0.0 + 0.018 + 0.132 avg prob of [Female] 0.9998306035995483\n",
            "loss 0.149 = 0.0 + 0.017 + 0.132 avg prob of [Female] 0.9998385310173035\n",
            "Delta norm: 60.64060974121094\n",
            "Change in target norm: 15.160152435302734 to 62.437747955322266 => 47.27759552001953\n",
            "Division Factor: 8.032464981079102\n",
            "Right vector norm: 7.549439907073975\n",
            "Computing left vector (u)...\n",
            "Selected u projection object John\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Name: John. Gender: | Token:  John\n",
            "Rewrite layer is 5\n",
            "Tying optimization objective to 27\n",
            "Recording initial value of v*\n",
            "loss 7.678 = 7.678 + 0.0 + 0.0 avg prob of [Female] 0.0005517443059943616\n",
            "loss 4.708 = 4.639 + 0.008 + 0.062 avg prob of [Female] 0.011820909567177296\n",
            "loss 2.659 = 2.544 + 0.018 + 0.097 avg prob of [Female] 0.07993774116039276\n",
            "loss 1.798 = 1.647 + 0.027 + 0.124 avg prob of [Female] 0.19750286638736725\n",
            "loss 0.932 = 0.781 + 0.027 + 0.124 avg prob of [Female] 0.4655205011367798\n",
            "loss 0.24 = 0.089 + 0.027 + 0.124 avg prob of [Female] 0.9152951240539551\n",
            "loss 0.16 = 0.009 + 0.026 + 0.124 avg prob of [Female] 0.9906166195869446\n",
            "loss 0.152 = 0.002 + 0.026 + 0.124 avg prob of [Female] 0.9980305433273315\n",
            "loss 0.15 = 0.001 + 0.025 + 0.124 avg prob of [Female] 0.9990109205245972\n",
            "loss 0.149 = 0.001 + 0.024 + 0.124 avg prob of [Female] 0.9992087483406067\n",
            "loss 0.148 = 0.001 + 0.023 + 0.124 avg prob of [Female] 0.9992749691009521\n",
            "loss 0.147 = 0.001 + 0.023 + 0.124 avg prob of [Female] 0.9993356466293335\n",
            "loss 0.147 = 0.001 + 0.022 + 0.124 avg prob of [Female] 0.9994106292724609\n",
            "loss 0.146 = 0.001 + 0.021 + 0.124 avg prob of [Female] 0.9994924068450928\n",
            "loss 0.145 = 0.0 + 0.02 + 0.124 avg prob of [Female] 0.9995704293251038\n",
            "loss 0.144 = 0.0 + 0.02 + 0.124 avg prob of [Female] 0.9996386170387268\n",
            "loss 0.144 = 0.0 + 0.019 + 0.124 avg prob of [Female] 0.9996951818466187\n",
            "loss 0.143 = 0.0 + 0.019 + 0.124 avg prob of [Female] 0.9997406005859375\n",
            "loss 0.142 = 0.0 + 0.018 + 0.124 avg prob of [Female] 0.9997767806053162\n",
            "loss 0.142 = 0.0 + 0.017 + 0.124 avg prob of [Female] 0.9998055696487427\n",
            "Delta norm: 64.40867614746094\n",
            "Change in target norm: 16.102169036865234 to 66.43238830566406 => 50.33021926879883\n",
            "Division Factor: 6.309397220611572\n",
            "Right vector norm: 10.208372116088867\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Kevin\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Name: Kevin. Gender: | Token:  Kevin\n",
            "Rewrite layer is 5\n",
            "Tying optimization objective to 27\n",
            "Recording initial value of v*\n",
            "loss 8.083 = 8.083 + 0.0 + 0.0 avg prob of [Female] 0.000374627357814461\n",
            "loss 5.69 = 5.611 + 0.012 + 0.066 avg prob of [Female] 0.004482856020331383\n",
            "loss 3.684 = 3.548 + 0.028 + 0.108 avg prob of [Female] 0.0306136105209589\n",
            "loss 2.368 = 2.203 + 0.036 + 0.129 avg prob of [Female] 0.11167410761117935\n",
            "loss 1.459 = 1.297 + 0.034 + 0.129 avg prob of [Female] 0.2753508388996124\n",
            "loss 0.774 = 0.612 + 0.032 + 0.129 avg prob of [Female] 0.548387348651886\n",
            "loss 0.304 = 0.144 + 0.031 + 0.129 avg prob of [Female] 0.868122398853302\n",
            "loss 0.172 = 0.013 + 0.031 + 0.129 avg prob of [Female] 0.9874957799911499\n",
            "loss 0.161 = 0.003 + 0.03 + 0.129 avg prob of [Female] 0.9973925948143005\n",
            "loss 0.159 = 0.002 + 0.029 + 0.129 avg prob of [Female] 0.9984530806541443\n",
            "loss 0.158 = 0.001 + 0.028 + 0.129 avg prob of [Female] 0.9986868500709534\n",
            "loss 0.157 = 0.001 + 0.027 + 0.129 avg prob of [Female] 0.9988347291946411\n",
            "loss 0.156 = 0.001 + 0.026 + 0.129 avg prob of [Female] 0.9990067481994629\n",
            "loss 0.154 = 0.001 + 0.025 + 0.129 avg prob of [Female] 0.9991918206214905\n",
            "loss 0.153 = 0.001 + 0.024 + 0.129 avg prob of [Female] 0.9993606805801392\n",
            "loss 0.152 = 0.001 + 0.023 + 0.129 avg prob of [Female] 0.9994983077049255\n",
            "loss 0.151 = 0.0 + 0.022 + 0.129 avg prob of [Female] 0.999603271484375\n",
            "loss 0.15 = 0.0 + 0.021 + 0.129 avg prob of [Female] 0.9996815919876099\n",
            "loss 0.149 = 0.0 + 0.02 + 0.129 avg prob of [Female] 0.9997392296791077\n",
            "loss 0.149 = 0.0 + 0.02 + 0.129 avg prob of [Female] 0.9997822046279907\n",
            "Delta norm: 62.072410583496094\n",
            "Change in target norm: 15.518102645874023 to 63.49606704711914 => 47.97796630859375\n",
            "Division Factor: 6.86788272857666\n",
            "Right vector norm: 9.038070678710938\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Terry\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Name: Terry. Gender: | Token:  Terry\n",
            "Rewrite layer is 5\n",
            "Tying optimization objective to 27\n",
            "Recording initial value of v*\n",
            "loss 6.607 = 6.607 + 0.0 + 0.0 avg prob of [Female] 0.001660961308516562\n",
            "loss 4.135 = 4.058 + 0.02 + 0.057 avg prob of [Female] 0.01990196853876114\n",
            "loss 1.728 = 1.579 + 0.059 + 0.091 avg prob of [Female] 0.20859868824481964\n",
            "loss 0.857 = 0.663 + 0.076 + 0.117 avg prob of [Female] 0.5166450142860413\n",
            "loss 0.542 = 0.369 + 0.053 + 0.12 avg prob of [Female] 0.6925778985023499\n",
            "loss 0.343 = 0.18 + 0.044 + 0.12 avg prob of [Female] 0.8358648419380188\n",
            "loss 0.246 = 0.086 + 0.04 + 0.12 avg prob of [Female] 0.917320191860199\n",
            "loss 0.202 = 0.046 + 0.036 + 0.12 avg prob of [Female] 0.9551090002059937\n",
            "loss 0.181 = 0.027 + 0.034 + 0.12 avg prob of [Female] 0.9729514718055725\n",
            "loss 0.169 = 0.018 + 0.032 + 0.12 avg prob of [Female] 0.9823579788208008\n",
            "loss 0.162 = 0.012 + 0.03 + 0.12 avg prob of [Female] 0.9878969192504883\n",
            "loss 0.157 = 0.009 + 0.029 + 0.12 avg prob of [Female] 0.9914382696151733\n",
            "loss 0.153 = 0.006 + 0.028 + 0.12 avg prob of [Female] 0.9938326478004456\n",
            "loss 0.151 = 0.004 + 0.027 + 0.12 avg prob of [Female] 0.995516836643219\n",
            "loss 0.149 = 0.003 + 0.026 + 0.12 avg prob of [Female] 0.9967342615127563\n",
            "loss 0.147 = 0.002 + 0.025 + 0.12 avg prob of [Female] 0.9976258277893066\n",
            "loss 0.145 = 0.002 + 0.024 + 0.12 avg prob of [Female] 0.9982819557189941\n",
            "loss 0.144 = 0.001 + 0.023 + 0.12 avg prob of [Female] 0.9987653493881226\n",
            "loss 0.143 = 0.001 + 0.022 + 0.12 avg prob of [Female] 0.999119758605957\n",
            "loss 0.142 = 0.001 + 0.022 + 0.12 avg prob of [Female] 0.999377429485321\n",
            "Delta norm: 66.8954849243164\n",
            "Change in target norm: 16.7238712310791 to 69.0845718383789 => 52.36070251464844\n",
            "Division Factor: 9.406187057495117\n",
            "Right vector norm: 7.1118597984313965\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Jonathan\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Name: Jonathan. Gender: | Token:  Jonathan\n",
            "Rewrite layer is 5\n",
            "Tying optimization objective to 27\n",
            "Recording initial value of v*\n",
            "loss 7.531 = 7.531 + 0.0 + 0.0 avg prob of [Female] 0.0006441142177209258\n",
            "loss 4.568 = 4.487 + 0.014 + 0.067 avg prob of [Female] 0.012944537214934826\n",
            "loss 2.451 = 2.316 + 0.028 + 0.107 avg prob of [Female] 0.09999619424343109\n",
            "loss 1.89 = 1.724 + 0.036 + 0.13 avg prob of [Female] 0.18099549412727356\n",
            "loss 1.238 = 1.075 + 0.033 + 0.13 avg prob of [Female] 0.3469674289226532\n",
            "loss 0.596 = 0.435 + 0.03 + 0.13 avg prob of [Female] 0.652135968208313\n",
            "loss 0.184 = 0.026 + 0.028 + 0.13 avg prob of [Female] 0.9748782515525818\n",
            "loss 0.158 = 0.002 + 0.027 + 0.13 avg prob of [Female] 0.9980655908584595\n",
            "loss 0.156 = 0.001 + 0.025 + 0.13 avg prob of [Female] 0.9988923072814941\n",
            "loss 0.155 = 0.001 + 0.024 + 0.13 avg prob of [Female] 0.9991483688354492\n",
            "loss 0.154 = 0.001 + 0.024 + 0.13 avg prob of [Female] 0.9992892146110535\n",
            "loss 0.153 = 0.001 + 0.023 + 0.13 avg prob of [Female] 0.9993693232536316\n",
            "loss 0.152 = 0.001 + 0.022 + 0.13 avg prob of [Female] 0.999419093132019\n",
            "loss 0.152 = 0.001 + 0.021 + 0.13 avg prob of [Female] 0.9994562268257141\n",
            "loss 0.151 = 0.001 + 0.021 + 0.13 avg prob of [Female] 0.9994901418685913\n",
            "loss 0.151 = 0.0 + 0.02 + 0.13 avg prob of [Female] 0.9995253682136536\n",
            "loss 0.15 = 0.0 + 0.02 + 0.13 avg prob of [Female] 0.9995629787445068\n",
            "loss 0.15 = 0.0 + 0.019 + 0.13 avg prob of [Female] 0.9996020197868347\n",
            "loss 0.149 = 0.0 + 0.019 + 0.13 avg prob of [Female] 0.9996410608291626\n",
            "loss 0.149 = 0.0 + 0.018 + 0.13 avg prob of [Female] 0.9996784925460815\n",
            "Delta norm: 61.60213851928711\n",
            "Change in target norm: 15.400534629821777 to 63.41517639160156 => 48.01464080810547\n",
            "Division Factor: 7.723330497741699\n",
            "Right vector norm: 7.976109981536865\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Douglas\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Name: Douglas. Gender: | Token:  Douglas\n",
            "Rewrite layer is 5\n",
            "Tying optimization objective to 27\n",
            "Recording initial value of v*\n",
            "loss 7.269 = 7.269 + 0.0 + 0.0 avg prob of [Female] 0.0008482509874738753\n",
            "loss 5.457 = 5.321 + 0.081 + 0.054 avg prob of [Female] 0.006412291433662176\n",
            "loss 2.723 = 2.526 + 0.11 + 0.087 avg prob of [Female] 0.08452195674180984\n",
            "loss 1.639 = 1.434 + 0.094 + 0.112 avg prob of [Female] 0.2435750961303711\n",
            "loss 1.042 = 0.843 + 0.083 + 0.116 avg prob of [Female] 0.43422600626945496\n",
            "loss 0.602 = 0.411 + 0.076 + 0.116 avg prob of [Female] 0.6647890210151672\n",
            "loss 0.379 = 0.19 + 0.072 + 0.116 avg prob of [Female] 0.8269044160842896\n",
            "loss 0.285 = 0.099 + 0.071 + 0.116 avg prob of [Female] 0.9060671925544739\n",
            "loss 0.241 = 0.056 + 0.068 + 0.116 avg prob of [Female] 0.9452756643295288\n",
            "loss 0.215 = 0.035 + 0.065 + 0.116 avg prob of [Female] 0.9658693671226501\n",
            "loss 0.198 = 0.023 + 0.059 + 0.116 avg prob of [Female] 0.9771596193313599\n",
            "loss 0.185 = 0.016 + 0.053 + 0.116 avg prob of [Female] 0.9837027192115784\n",
            "loss 0.176 = 0.012 + 0.047 + 0.116 avg prob of [Female] 0.9877310395240784\n",
            "loss 0.169 = 0.01 + 0.043 + 0.116 avg prob of [Female] 0.9903604388237\n",
            "loss 0.164 = 0.008 + 0.04 + 0.116 avg prob of [Female] 0.9921871423721313\n",
            "loss 0.16 = 0.006 + 0.038 + 0.116 avg prob of [Female] 0.9935451745986938\n",
            "loss 0.157 = 0.005 + 0.036 + 0.116 avg prob of [Female] 0.9946205019950867\n",
            "loss 0.154 = 0.004 + 0.034 + 0.116 avg prob of [Female] 0.9955131411552429\n",
            "loss 0.152 = 0.004 + 0.032 + 0.116 avg prob of [Female] 0.9962766766548157\n",
            "loss 0.15 = 0.003 + 0.031 + 0.116 avg prob of [Female] 0.9969406127929688\n",
            "Delta norm: 68.94843292236328\n",
            "Change in target norm: 17.23710823059082 to 70.4540786743164 => 53.21697235107422\n",
            "Division Factor: 8.272417068481445\n",
            "Right vector norm: 8.334738731384277\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Peter\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Name: Peter. Gender: | Token:  Peter\n",
            "Rewrite layer is 5\n",
            "Tying optimization objective to 27\n",
            "Recording initial value of v*\n",
            "loss 7.798 = 7.798 + 0.0 + 0.0 avg prob of [Female] 0.00048648464144207537\n",
            "loss 5.388 = 5.313 + 0.013 + 0.062 avg prob of [Female] 0.006269720382988453\n",
            "loss 2.998 = 2.873 + 0.025 + 0.1 avg prob of [Female] 0.05844490975141525\n",
            "loss 2.075 = 1.915 + 0.035 + 0.125 avg prob of [Female] 0.14822746813297272\n",
            "loss 1.293 = 1.135 + 0.033 + 0.125 avg prob of [Female] 0.3251080811023712\n",
            "loss 0.645 = 0.489 + 0.03 + 0.125 avg prob of [Female] 0.6203718781471252\n",
            "loss 0.194 = 0.04 + 0.029 + 0.125 avg prob of [Female] 0.9612231850624084\n",
            "loss 0.157 = 0.005 + 0.027 + 0.125 avg prob of [Female] 0.9950743317604065\n",
            "loss 0.153 = 0.002 + 0.026 + 0.125 avg prob of [Female] 0.9978792071342468\n",
            "loss 0.152 = 0.002 + 0.025 + 0.125 avg prob of [Female] 0.9984012842178345\n",
            "loss 0.151 = 0.001 + 0.025 + 0.125 avg prob of [Female] 0.9986764788627625\n",
            "loss 0.15 = 0.001 + 0.024 + 0.125 avg prob of [Female] 0.998950719833374\n",
            "loss 0.149 = 0.001 + 0.023 + 0.125 avg prob of [Female] 0.9991735816001892\n",
            "loss 0.148 = 0.001 + 0.023 + 0.125 avg prob of [Female] 0.9993293881416321\n",
            "loss 0.148 = 0.001 + 0.022 + 0.125 avg prob of [Female] 0.9994365572929382\n",
            "loss 0.147 = 0.0 + 0.021 + 0.125 avg prob of [Female] 0.9995144605636597\n",
            "loss 0.146 = 0.0 + 0.021 + 0.125 avg prob of [Female] 0.999575138092041\n",
            "loss 0.145 = 0.0 + 0.02 + 0.125 avg prob of [Female] 0.9996252059936523\n",
            "loss 0.145 = 0.0 + 0.02 + 0.125 avg prob of [Female] 0.9996680617332458\n",
            "loss 0.144 = 0.0 + 0.019 + 0.125 avg prob of [Female] 0.9997053146362305\n",
            "Delta norm: 64.00141143798828\n",
            "Change in target norm: 16.000354766845703 to 65.6864013671875 => 49.6860466003418\n",
            "Division Factor: 7.363269805908203\n",
            "Right vector norm: 8.691983222961426\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Luke\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Name: Luke. Gender: | Token:  Luke\n",
            "Rewrite layer is 5\n",
            "Tying optimization objective to 27\n",
            "Recording initial value of v*\n",
            "loss 7.811 = 7.811 + 0.0 + 0.0 avg prob of [Female] 0.0004741125740110874\n",
            "loss 5.501 = 5.439 + 0.01 + 0.052 avg prob of [Female] 0.005373087245970964\n",
            "loss 3.012 = 2.904 + 0.024 + 0.083 avg prob of [Female] 0.05853921175003052\n",
            "loss 1.746 = 1.6 + 0.038 + 0.108 avg prob of [Female] 0.20489375293254852\n",
            "loss 0.888 = 0.732 + 0.042 + 0.114 avg prob of [Female] 0.4843677878379822\n",
            "loss 0.449 = 0.293 + 0.043 + 0.114 avg prob of [Female] 0.7479438185691833\n",
            "loss 0.28 = 0.124 + 0.042 + 0.114 avg prob of [Female] 0.8836290240287781\n",
            "loss 0.212 = 0.059 + 0.039 + 0.114 avg prob of [Female] 0.9429860711097717\n",
            "loss 0.18 = 0.03 + 0.036 + 0.114 avg prob of [Female] 0.9700851440429688\n",
            "loss 0.164 = 0.017 + 0.033 + 0.114 avg prob of [Female] 0.9835532307624817\n",
            "loss 0.155 = 0.009 + 0.031 + 0.114 avg prob of [Female] 0.9906787276268005\n",
            "loss 0.15 = 0.005 + 0.03 + 0.114 avg prob of [Female] 0.9945662617683411\n",
            "loss 0.146 = 0.003 + 0.029 + 0.114 avg prob of [Female] 0.9967434406280518\n",
            "loss 0.143 = 0.002 + 0.027 + 0.114 avg prob of [Female] 0.9980069994926453\n",
            "loss 0.141 = 0.001 + 0.026 + 0.114 avg prob of [Female] 0.9987553358078003\n",
            "loss 0.139 = 0.001 + 0.024 + 0.114 avg prob of [Female] 0.9992104768753052\n",
            "loss 0.137 = 0.001 + 0.022 + 0.114 avg prob of [Female] 0.9994896054267883\n",
            "loss 0.136 = 0.0 + 0.021 + 0.114 avg prob of [Female] 0.9996585845947266\n",
            "loss 0.135 = 0.0 + 0.021 + 0.114 avg prob of [Female] 0.9997603297233582\n",
            "loss 0.134 = 0.0 + 0.02 + 0.114 avg prob of [Female] 0.9998204708099365\n",
            "Delta norm: 70.24494934082031\n",
            "Change in target norm: 17.561237335205078 to 71.91045379638672 => 54.34921646118164\n",
            "Division Factor: 8.679702758789062\n",
            "Right vector norm: 8.093012809753418\n",
            "Computing left vector (u)...\n",
            "Selected u projection object David\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Name: David. Gender: | Token:  David\n",
            "Rewrite layer is 5\n",
            "Tying optimization objective to 27\n",
            "Recording initial value of v*\n",
            "loss 7.96 = 7.96 + 0.0 + 0.0 avg prob of [Female] 0.0004128815489821136\n",
            "loss 5.484 = 5.404 + 0.008 + 0.072 avg prob of [Female] 0.0056363968178629875\n",
            "loss 3.229 = 3.097 + 0.017 + 0.114 avg prob of [Female] 0.04696505516767502\n",
            "loss 2.302 = 2.146 + 0.022 + 0.134 avg prob of [Female] 0.11881586909294128\n",
            "loss 1.557 = 1.401 + 0.022 + 0.134 avg prob of [Female] 0.2485678642988205\n",
            "loss 0.812 = 0.657 + 0.021 + 0.134 avg prob of [Female] 0.5442972779273987\n",
            "loss 0.213 = 0.058 + 0.022 + 0.134 avg prob of [Female] 0.9443314075469971\n",
            "loss 0.161 = 0.006 + 0.021 + 0.134 avg prob of [Female] 0.994418203830719\n",
            "loss 0.158 = 0.003 + 0.021 + 0.134 avg prob of [Female] 0.9969108700752258\n",
            "loss 0.157 = 0.002 + 0.021 + 0.134 avg prob of [Female] 0.9978057742118835\n",
            "loss 0.156 = 0.002 + 0.02 + 0.134 avg prob of [Female] 0.9982469081878662\n",
            "loss 0.155 = 0.001 + 0.02 + 0.134 avg prob of [Female] 0.9985336065292358\n",
            "loss 0.155 = 0.001 + 0.019 + 0.134 avg prob of [Female] 0.9987735152244568\n",
            "loss 0.154 = 0.001 + 0.019 + 0.134 avg prob of [Female] 0.9989833831787109\n",
            "loss 0.153 = 0.001 + 0.018 + 0.134 avg prob of [Female] 0.9991622567176819\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92m<cell line: 3>\u001b[0m:\u001b[94m3\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92m<listcomp>\u001b[0m:\u001b[94m3\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92mget_value\u001b[0m:\u001b[94m33\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92mben_compute_v\u001b[0m:\u001b[94m158\u001b[0m                                                                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/\u001b[0m\u001b[1;33m_tensor.py\u001b[0m:\u001b[94m487\u001b[0m in \u001b[92mbackward\u001b[0m                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 484 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mcreate_graph=create_graph,                                                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 485 \u001b[0m\u001b[2m│   │   │   │   \u001b[0minputs=inputs,                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 486 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 487 \u001b[2m│   │   \u001b[0mtorch.autograd.backward(                                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 488 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m, gradient, retain_graph, create_graph, inputs=inputs                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 489 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 490 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/autograd/\u001b[0m\u001b[1;33m__init__.py\u001b[0m:\u001b[94m200\u001b[0m in \u001b[92mbackward\u001b[0m               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m197 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# The reason we repeat same the comment below is that\u001b[0m                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m198 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# some Python versions print out the first line of a multi-line function\u001b[0m               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m199 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# calls in the traceback and some print out the last line\u001b[0m                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m200 \u001b[2m│   \u001b[0mVariable._execution_engine.run_backward(  \u001b[2m# Calls into the C++ engine to run the bac\u001b[0m   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m201 \u001b[0m\u001b[2m│   │   \u001b[0mtensors, grad_tensors_, retain_graph, create_graph, inputs,                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m202 \u001b[0m\u001b[2m│   │   \u001b[0mallow_unreachable=\u001b[94mTrue\u001b[0m, accumulate_grad=\u001b[94mTrue\u001b[0m)  \u001b[2m# Calls into the C++ engine to ru\u001b[0m   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m203 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 3&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;listcomp&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_value</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">33</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">ben_compute_v</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">158</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_tensor.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">487</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 484 │   │   │   │   </span>create_graph=create_graph,                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 485 │   │   │   │   </span>inputs=inputs,                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 486 │   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 487 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>torch.autograd.backward(                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 488 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, gradient, retain_graph, create_graph, inputs=inputs                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 489 │   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 490 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/autograd/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">__init__.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">200</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">197 │   # The reason we repeat same the comment below is that</span>                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">198 │   # some Python versions print out the first line of a multi-line function</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">199 │   # calls in the traceback and some print out the last line</span>                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>200 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>Variable._execution_engine.run_backward(  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Calls into the C++ engine to run the bac</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">201 │   │   </span>tensors, grad_tensors_, retain_graph, create_graph, inputs,                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">202 │   │   </span>allow_unreachable=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>, accumulate_grad=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Calls into the C++ engine to ru</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">203 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "famous_names = ['Barack Obama', 'Joe Biden', 'Donald Trump',\n",
        "                'Kamala Harris', 'Hilary Clinton', 'Mona Lisa',\n",
        "                'Caitlin Jenner', 'Bruce Jenner']\n",
        "famous_deltas = [get_value(name, model, tok, hparams, hparams.layers[0], \"Female\", \"Name: {}. Gender:\") for name in famous_names]\n"
      ],
      "metadata": {
        "id": "ImcVtozlgMeM"
      },
      "id": "ImcVtozlgMeM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "object_names = ['Dress', 'Hammer', 'Lipstick', 'Car', 'Scimitar', 'Kevlar', 'Dreadnought', 'Shopping', 'Cooking', 'Baking', 'Knitting']\n",
        "object_deltas = [get_value(name, model, tok, hparams, hparams.layers[0], \"Female\", \"Name: {}. Gender:\") for name in object_names]\n"
      ],
      "metadata": {
        "id": "L0xX6WpKhY1D"
      },
      "id": "L0xX6WpKhY1D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pycountry\n",
        "# import pycountry\n",
        "# countries = [c.name for c in pycountry.countries]\n",
        "# hparams.v_num_grad_steps = 10\n",
        "# country_deltas = [get_value(l, model, tok, hparams, hparams.layers[0], \"Europe\", \"{} is in the continent of \")[\"delta\"] for l in countries]"
      ],
      "metadata": {
        "id": "q6UCfeN8NeV8"
      },
      "id": "q6UCfeN8NeV8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# values_matrix = torch.cat(values)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "sc = StandardScaler()\n",
        "\n",
        "np_values = np.array([v.detach().cpu().clone().numpy() for v in name_deltas_female]) #- np.array([v.detach().cpu().clone().numpy() for v in london_deltas]).T\n",
        "print(np_values.shape)\n",
        "sc.fit(np_values)\n",
        "X_train_std = sc.transform(np_values)\n",
        "#\n",
        "# Instantiate PCA\n",
        "#\n",
        "pca = PCA()\n",
        "#\n",
        "# Determine transformed features\n",
        "#\n",
        "X_train_pca = pca.fit_transform(X_train_std)\n",
        "#\n",
        "# Determine explained variance using explained_variance_ration_ attribute\n",
        "#\n",
        "exp_var_pca = pca.explained_variance_ratio_\n",
        "#\n",
        "# Cumulative sum of eigenvalues; This will be used to create step plot\n",
        "# for visualizing the variance explained by each principal component.\n",
        "#\n",
        "cum_sum_eigenvalues = np.cumsum(exp_var_pca)\n",
        "#\n",
        "# Create the visualization plot\n",
        "#\n",
        "plt.bar(range(0,len(exp_var_pca)), exp_var_pca, alpha=0.5, align='center', label='Individual explained variance')\n",
        "plt.step(range(0,len(cum_sum_eigenvalues)), cum_sum_eigenvalues, where='mid',label='Cumulative explained variance')\n",
        "plt.ylabel('Explained variance ratio')\n",
        "plt.xlabel('Principal component index')\n",
        "plt.legend(loc='best')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "print('explained variance',pca.explained_variance_ratio_[0:3])\n",
        "\n",
        "# pca_1 = PCA(n_components = 1)\n",
        "# pca_1.fit(np_values)\n",
        "transformed = pca.transform(np_values)\n",
        "# print(transformed[0])\n",
        "df = pd.DataFrame(zip(transformed[0], female_names), columns = [\"pc1\", \"name\"] )\n",
        "df"
      ],
      "metadata": {
        "id": "pFFiusx6Lj7f"
      },
      "id": "pFFiusx6Lj7f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unit_vector(vector):\n",
        "    \"\"\" Returns the unit vector of the vector.  \"\"\"\n",
        "    return vector / np.linalg.norm(vector)\n",
        "\n",
        "def angle_between(v1, v2):\n",
        "    \"\"\" Returns the angle in radians between vectors 'v1' and 'v2'::\n",
        "\n",
        "            >>> angle_between((1, 0, 0), (0, 1, 0))\n",
        "            1.5707963267948966\n",
        "            >>> angle_between((1, 0, 0), (1, 0, 0))\n",
        "            0.0\n",
        "            >>> angle_between((1, 0, 0), (-1, 0, 0))\n",
        "            3.141592653589793\n",
        "    \"\"\"\n",
        "    v1_u = unit_vector(v1)\n",
        "    v2_u = unit_vector(v2)\n",
        "    return np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0))\n",
        "\n",
        "def first_pc(deltas):\n",
        "  sc = StandardScaler()\n",
        "  np_values = np.array([v.detach().cpu().clone().numpy() for v in deltas])\n",
        "  sc.fit(np_values)\n",
        "  X_train_std = sc.transform(np_values)\n",
        "  pca = PCA()\n",
        "  X_train_pca = pca.fit_transform(X_train_std)\n",
        "  print(\"% explained by first pc: \", pca.explained_variance_ratio_[0])\n",
        "  return pca.components_[0]\n",
        "\n",
        "male_pc = first_pc(name_deltas_male)\n",
        "female_pc = first_pc(name_deltas_female)\n",
        "print('Angle:', angle_between(male_pc, female_pc))\n"
      ],
      "metadata": {
        "id": "Ay8z5TIsaPCo"
      },
      "id": "Ay8z5TIsaPCo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "angle_between(\n",
        "    np.mean([v.detach().cpu().clone().numpy() for v in name_deltas_male], 0),\n",
        "    np.mean([v.detach().cpu().clone().numpy() for v in name_deltas_female], 0)\n",
        ")\n"
      ],
      "metadata": {
        "id": "Q6kwZw5jfMyI"
      },
      "id": "Q6kwZw5jfMyI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "with open('/content/drive/My Drive/name_deltas_female_left.txt', 'r') as f:\n",
        "  name_deltas_female_left = np.loadtxt(f)\n",
        "with open('/content/drive/My Drive/name_deltas_female_delta.txt', 'r') as f:\n",
        "  name_deltas_female_delta = np.loadtxt(f)\n",
        "with open('/content/drive/My Drive/name_deltas_female_right.txt', 'r') as f:\n",
        "  name_deltas_female_right = np.loadtxt(f)\n",
        "with open('/content/drive/My Drive/name_deltas_male_left.txt', 'r') as f:\n",
        "  name_deltas_male_left = np.loadtxt(f)\n",
        "with open('/content/drive/My Drive/name_deltas_male_right.txt', 'r') as f:\n",
        "  name_deltas_male_right = np.loadtxt(f)\n",
        "with open('/content/drive/My Drive/name_deltas_male_delta.txt', 'r') as f:\n",
        "  name_deltas_male_delta = np.loadtxt(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56wvso0rT2vR",
        "outputId": "ec14df83-883b-492d-9a85-a14413ef93da"
      },
      "id": "56wvso0rT2vR",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-2191bb46aa1f>:4: UserWarning: loadtxt: Empty input file: \"<_io.TextIOWrapper name='/content/drive/My Drive/name_deltas_female_left.txt' mode='r' encoding='UTF-8'>\"\n",
            "  name_deltas_female_left = np.loadtxt(f)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import random\n",
        "# extract_value = lambda v: v['left_vector'].detach().cpu().clone().numpy()\n",
        "print(name_deltas_female_right.shape)\n",
        "print(name_deltas_male_right.shape)\n",
        "X = np.concatenate((name_deltas_male_delta, name_deltas_female_delta), axis=0)\n",
        "labels = ['male' for _ in name_deltas_male_delta] + ['female' for _ in name_deltas_female_delta]\n",
        "print(X.shape)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=0)\n",
        "svm = SVC(kernel='linear', C=1)\n",
        "svm.fit(X_train, y_train)\n",
        "y_pred = svm.predict(X_test)\n",
        "\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
        "print('Precision:', precision_score(y_test, y_pred, average='weighted'))\n",
        "print('Recall:', recall_score(y_test, y_pred, average='weighted'))\n",
        "print('F1-score:', f1_score(y_test, y_pred, average='weighted'))\n",
        "print(svm.support_vectors_.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12qqLEgZf6UC",
        "outputId": "3a91cc18-fd4c-4460-a621-fda2d6b81030"
      },
      "id": "12qqLEgZf6UC",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(500, 4096)\n",
            "(500, 4096)\n",
            "(1000, 4096)\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "(64, 4096)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "linear_svm = LinearSVC()\n",
        "\n",
        "# Train the LinearSVC classifier on the training set\n",
        "linear_svm.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels of the test set\n",
        "y_pred = linear_svm.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "accuracy = linear_svm.score(X_test, y_test)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(linear_svm.coef_.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCDkAqR6jsvk",
        "outputId": "39f625bc-6055-465e-b99f-782de0d193b7"
      },
      "id": "GCDkAqR6jsvk",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "(1, 4096)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize import least_squares\n",
        "res = least_squares(lambda x: (linear_svm.coef_ @ x), np.zeros(4096), bounds=(-1,1))\n",
        "res.x"
      ],
      "metadata": {
        "id": "6IVGF5cBJ1JA"
      },
      "id": "6IVGF5cBJ1JA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize import minimize\n",
        "from scipy.optimize import Bounds\n",
        "bounds = Bounds([-1  for _ in range(0, 4096)], [1  for _ in range(0, 4096)]) #*[[-1, 1] for _ in range(0, 4096)])\n",
        "m=minimize(lambda x: (linear_svm.coef_ @ x), np.zeros(4096), bounds=bounds)\n",
        "np.sum(m.x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0q7CU-QLa5N",
        "outputId": "152a1fb4-e58b-4fb5-e79e-db0a13842d15"
      },
      "id": "K0q7CU-QLa5N",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-5.48160667282894"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_svm.coef_"
      ],
      "metadata": {
        "id": "mMlQL74FMaAD"
      },
      "id": "mMlQL74FMaAD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "linear_df = pd.DataFrame([[X_train[i], y_train[i], linear_svm.predict([X_train[i]])[0], linear_svm.coef_ @ X_train[i]] for i in range(0,700)])\n",
        "linear_df"
      ],
      "metadata": {
        "id": "TTLsH0p7IRpu"
      },
      "id": "TTLsH0p7IRpu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_svm.coef_ @ X_train[0]\n",
        "X_train.T @ X_train\n",
        "np.mean([X_train[idx] @ X_train[idx] for idx in range(0,700)])"
      ],
      "metadata": {
        "id": "VzmKq_AcHLXg"
      },
      "id": "VzmKq_AcHLXg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_avg = np.mean(name_deltas_male_delta, 0)\n",
        "avg_orthogonal = avg - linear_svm.coef_.T * np.dot(avg, linear_svm.coef_.T)\n",
        "angle_between(avg_orthogonal, linear_svm.coef_.T)\n",
        "# np.mean(name_deltas_male_right, 0).shape"
      ],
      "metadata": {
        "id": "uPS4_S1iN2-y"
      },
      "id": "uPS4_S1iN2-y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_value(v, col = 'right_vector'):\n",
        "  return v[col].detach().cpu().clone().numpy()\n",
        "\n",
        "def run_extract(deltas, col = 'right_vector'):\n",
        "  return [extract_value(v, col) for v in deltas]\n",
        "# object_df = pd.DataFrame(zip(run_extract(object_deltas,'left_vector'), run_extract(object_deltas, 'delta'), object_names), columns = [\"left_vector\", 'delta', \"name\"] )\n",
        "# object_df"
      ],
      "metadata": {
        "id": "IA71BCWTh22v"
      },
      "id": "IA71BCWTh22v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name_deltas_female_right"
      ],
      "metadata": {
        "id": "Gwswl3aeMrCt"
      },
      "id": "Gwswl3aeMrCt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_svm.predict(run_extract(object_deltas))\n",
        "# np.array(object_df['left_vector'])"
      ],
      "metadata": {
        "id": "UOIXUmoujIAh"
      },
      "id": "UOIXUmoujIAh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_svm.predict(run_extract(famous_deltas,'left_vector'))"
      ],
      "metadata": {
        "id": "-8agTIgckJ1y"
      },
      "id": "-8agTIgckJ1y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install factor-analyzer"
      ],
      "metadata": {
        "id": "aEIIo8oEqHvZ"
      },
      "id": "aEIIo8oEqHvZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from factor_analyzer import FactorAnalyzer\n",
        "\n",
        "# data = np.random.rand(100, 10)\n",
        "\n",
        "# # Perform factor analysis with k=2 factors\n",
        "# fa = FactorAnalyzer(n_factors=2, rotation=None, is_corr_matrix=False)\n",
        "# fa.fit(data, normalize = True)\n",
        "\n",
        "# # Get the factor loadings and scores\n",
        "# loadings = fa.loadings_ \n",
        "# scores = fa.transform(data)\n",
        "\n",
        "# # PCA on the factor scores \n",
        "# fa_pca = PCA(n_components=2)\n",
        "# fa_pca.fit(scores)\n",
        "\n",
        "# # Project PCs onto factor loadings\n",
        "# pc_project = fa_pca.components_.dot(loadings.T)  \n",
        "\n",
        "# # Reconstruct original data from factor scores \n",
        "# recon = scores.dot(pc_project)\n",
        "\n",
        "# factor_variances = fa.get_factor_variance()\n",
        "# print(factor_variances[0]/np.sum(factor_variances))\n",
        "# # print(recon)\n",
        "\n",
        "# def first_factor(deltas):\n",
        "#   sc = StandardScaler()\n",
        "#   np_values = np.array([v.detach().cpu().clone().numpy() for v in deltas]).T\n",
        "#   sc.fit(np_values)\n",
        "#   X_train_std = sc.transform(np_values)\n",
        "#   pca = PCA()\n",
        "#   X_train_pca = pca.fit_transform(X_train_std)\n",
        "#   print(\"% explained by first pc: \", pca.explained_variance_ratio_[0])\n",
        "#   return pca.components_[0]\n"
      ],
      "metadata": {
        "id": "afaWlad5p_q5"
      },
      "id": "afaWlad5p_q5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tok(\"Name: Brittany. Gender:\", return_tensors=\"pt\").to(\"cuda\")\n",
        "outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
        "logits = outputs.logits\n",
        "logits.shape"
      ],
      "metadata": {
        "id": "MIiwsIiccBtm"
      },
      "id": "MIiwsIiccBtm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs[\"input_ids\"]\n",
        "logits[0, -1, tok.get_vocab()[\"word\"]]\n",
        "import torch.nn.functional as F\n",
        "\n",
        "probs = F.softmax(logits, dim=-1)\n",
        "probs[0, -1, tok.get_vocab()[\"Female\"]]\n",
        "\n",
        "predicted_classes = logits.argmax(-1) \n",
        "tok.decode(predicted_classes[0,-1])"
      ],
      "metadata": {
        "id": "bKby97t2eNr1"
      },
      "id": "bKby97t2eNr1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mf_prob(name):\n",
        "  inputs = tok(f\"Name: {name}. Gender:\", return_tensors=\"pt\").to(\"cuda\")\n",
        "  outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
        "  logits = outputs.logits\n",
        "  probs = F.softmax(logits, dim=-1)\n",
        "  return {'Female': probs[0, -1, tok.get_vocab()[\"Female\"]], 'Male': probs[0, -1, tok.get_vocab()[\"Male\"]]}\n",
        "\n",
        "df['male_prob'] = df['name'].apply(lambda v: mf_prob(v)['Male'])\n",
        "df['female_prob'] = df['name'].apply(lambda v: mf_prob(v)['Female'])\n",
        "plt.scatter(df['female_prob'], df['pc1'])"
      ],
      "metadata": {
        "id": "-WiPLruqlBYe"
      },
      "id": "-WiPLruqlBYe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(df['male_prob'], df['pc1'])"
      ],
      "metadata": {
        "id": "aSfJwBWWmJvN"
      },
      "id": "aSfJwBWWmJvN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rome.rome_main import upd_matrix_match_shape\n",
        "\n",
        "def new_v_from_delta(\n",
        "    model: AutoModelForCausalLM,\n",
        "    tok: AutoTokenizer,\n",
        "    request: Dict,\n",
        "    hparams: ROMEHyperParams,\n",
        "    layer: int,\n",
        "    left_vector: torch.Tensor,\n",
        "    context_templates: List[str],\n",
        "    delta_override\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Computes the value (right) vector for the rank-1 update.\n",
        "    Runs a simple optimization procedure.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"Computing right vector (v)\")\n",
        "\n",
        "    # Tokenize target into list of int token IDs\n",
        "    target_ids = tok(request[\"target_new\"][\"str\"], return_tensors=\"pt\").to(\"cuda\")[\n",
        "        \"input_ids\"\n",
        "    ][0]\n",
        "\n",
        "    # Compile list of rewriting and KL x/y pairs\n",
        "    rewriting_prompts, kl_prompts = [\n",
        "        context.format(request[\"prompt\"]) + tok.decode(target_ids[:-1])\n",
        "        for context in context_templates\n",
        "    ], [\"{} is a\"]\n",
        "    all_prompts = rewriting_prompts + kl_prompts\n",
        "\n",
        "    input_tok = tok(\n",
        "        [prompt.format(request[\"subject\"]) for prompt in all_prompts],\n",
        "        return_tensors=\"pt\",\n",
        "        padding=True,\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    # Compute rewriting targets\n",
        "    rewriting_targets = torch.tensor(-100, device=\"cuda\").repeat(\n",
        "        len(rewriting_prompts), *input_tok[\"input_ids\"].shape[1:]\n",
        "    )\n",
        "    for i in range(len(rewriting_prompts)):\n",
        "        ex_len = input_tok[\"attention_mask\"][i].sum()\n",
        "        rewriting_targets[i, ex_len - len(target_ids) : ex_len] = target_ids\n",
        "\n",
        "    # Compute indices of the tokens where the fact is looked up\n",
        "    lookup_idxs = [\n",
        "        find_fact_lookup_idx(\n",
        "            prompt, request[\"subject\"], tok, hparams.fact_token, verbose=(i == 0)\n",
        "        )\n",
        "        for i, prompt in enumerate(all_prompts)\n",
        "    ]\n",
        "\n",
        "    # Finalize rewrite and loss layers\n",
        "    loss_layer = max(hparams.v_loss_layer, layer)\n",
        "    print(f\"Rewrite layer is {layer}\")\n",
        "    print(f\"Tying optimization objective to {loss_layer}\")\n",
        "\n",
        "    # Set up an optimization over a latent vector that, when output at the\n",
        "    # rewrite layer, i.e. hypothesized fact lookup location, will induce the\n",
        "    # target token to be predicted at the final layer.\n",
        "    delta = torch.zeros((model.config.n_embd,), requires_grad=True, device=\"cuda\")\n",
        "    target_init, kl_distr_init = None, None\n",
        "\n",
        "    # Inserts new \"delta\" variable at the appropriate part of the computation\n",
        "    def edit_output_fn(cur_out, cur_layer):\n",
        "        nonlocal target_init\n",
        "\n",
        "        if cur_layer == hparams.mlp_module_tmp.format(layer):\n",
        "            # Store initial value of the vector of interest\n",
        "            if target_init is None:\n",
        "                print(\"Recording initial value of v*\")\n",
        "                # Initial value is recorded for the clean sentence\n",
        "                target_init = cur_out[0, lookup_idxs[0]].detach().clone()\n",
        "\n",
        "            for i, idx in enumerate(lookup_idxs):\n",
        "                cur_out[i, idx, :] += delta\n",
        "\n",
        "        return cur_out\n",
        "\n",
        "    # Optimizer\n",
        "    opt = torch.optim.Adam([delta], lr=hparams.v_lr)\n",
        "    nethook.set_requires_grad(False, model)\n",
        "\n",
        "    # Execute optimization\n",
        "    opt.zero_grad()\n",
        "\n",
        "    # Forward propagation\n",
        "    with nethook.TraceDict(\n",
        "        module=model,\n",
        "        layers=[\n",
        "            hparams.layer_module_tmp.format(loss_layer),\n",
        "            hparams.mlp_module_tmp.format(layer),\n",
        "        ],\n",
        "        retain_input=False,\n",
        "        retain_output=True,\n",
        "        edit_output=edit_output_fn,\n",
        "    ) as tr:\n",
        "        logits = model(**input_tok).logits\n",
        "\n",
        "        # Compute distribution for KL divergence\n",
        "        kl_logits = torch.stack(\n",
        "            [\n",
        "                logits[i - len(kl_prompts), idx, :]\n",
        "                for i, idx in enumerate(lookup_idxs[-len(kl_prompts) :])\n",
        "            ],\n",
        "            dim=0,\n",
        "        )\n",
        "        kl_log_probs = torch.nn.functional.log_softmax(kl_logits, dim=1)\n",
        "        if kl_distr_init is None:\n",
        "            kl_distr_init = kl_log_probs.detach().clone()\n",
        "    print('Shapes:', target_init.shape, delta.shape, delta_override.shape)\n",
        "    target = target_init + delta_override\n",
        "\n",
        "    # Retrieve cur_input, the current input to the 2nd MLP layer, and\n",
        "    # cur_output, the original output of the 2nd MLP layer.\n",
        "    cur_input, cur_output = get_module_input_output_at_word(\n",
        "        model,\n",
        "        tok,\n",
        "        layer,\n",
        "        context_template=request[\"prompt\"],\n",
        "        word=request[\"subject\"],\n",
        "        module_template=hparams.rewrite_module_tmp,\n",
        "        fact_token_strategy=hparams.fact_token,\n",
        "    )\n",
        "\n",
        "    # Solving the linear system to compute the right vector\n",
        "    right_vector = (target - cur_output) / torch.dot(cur_input, left_vector)\n",
        "    print(f\"Delta norm: {(target - cur_output).norm().item()}\")\n",
        "    print(\n",
        "        f\"Change in target norm: {target_init.norm().item()} to {target.norm().item()} => {(target.norm() - target_init.norm()).item()}\"\n",
        "    )\n",
        "    print(f\"Division Factor: {torch.dot(cur_input, left_vector).item()}\")\n",
        "    print(f\"Right vector norm: {right_vector.norm()}\")\n",
        "\n",
        "    return right_vector\n",
        "\n",
        "def execute_rome_delta_override(\n",
        "    model: AutoModelForCausalLM,\n",
        "    tok: AutoTokenizer,\n",
        "    request: Dict,\n",
        "    hparams: ROMEHyperParams,\n",
        "    delta_override\n",
        ") -> Dict[str, Tuple[torch.Tensor]]:\n",
        "    \"\"\"\n",
        "    Executes the ROME update algorithm for the specified update at the specified layer\n",
        "    Invariant: model at beginning of function == model at end of function\n",
        "    \"\"\"\n",
        "\n",
        "    # Update target and print info\n",
        "    request = deepcopy(request)\n",
        "    if request[\"target_new\"][\"str\"][0] != \" \":\n",
        "        # Space required for correct tokenization\n",
        "        request[\"target_new\"][\"str\"] = \" \" + request[\"target_new\"][\"str\"]\n",
        "    print(\n",
        "        f\"Executing ROME algorithm for the update: \"\n",
        "        f\"[{request['prompt'].format(request['subject'])}] -> [{request['target_new']['str']}]\"\n",
        "    )\n",
        "\n",
        "    # Retrieve weights that user desires to change\n",
        "    weights = {\n",
        "        f\"{hparams.rewrite_module_tmp.format(layer)}.weight\": nethook.get_parameter(\n",
        "            model, f\"{hparams.rewrite_module_tmp.format(layer)}.weight\"\n",
        "        )\n",
        "        for layer in hparams.layers\n",
        "    }\n",
        "    # Save old weights for future restoration\n",
        "    weights_copy = {k: v.detach().clone() for k, v in weights.items()}\n",
        "\n",
        "    # Update loop: sequentially intervene at each specified layer\n",
        "    deltas = {}\n",
        "    for layer in sorted(hparams.layers):\n",
        "        # Compute rank-1 update matrix\n",
        "        left_vector: torch.Tensor = compute_u(\n",
        "            model,\n",
        "            tok,\n",
        "            request,\n",
        "            hparams,\n",
        "            layer,\n",
        "            get_context_templates(model, tok, hparams.context_template_length_params),\n",
        "        )\n",
        "        print(\"Left vector shape:\", left_vector.shape)\n",
        "        right_vector: torch.Tensor = new_v_from_delta(\n",
        "            model,\n",
        "            tok,\n",
        "            request,\n",
        "            hparams,\n",
        "            layer,\n",
        "            left_vector,\n",
        "            get_context_templates(model, tok, hparams.context_template_length_params),\n",
        "            delta_override\n",
        "        )\n",
        "        print(\"Right vector shape:\", right_vector.shape)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Determine correct transposition of delta matrix\n",
        "            weight_name = f\"{hparams.rewrite_module_tmp.format(layer)}.weight\"\n",
        "            upd_matrix = left_vector.unsqueeze(1) @ right_vector.unsqueeze(0)\n",
        "            upd_matrix = upd_matrix_match_shape(upd_matrix, weights[weight_name].shape)\n",
        "\n",
        "            # Update model weights and record desired changes in `delta` variable\n",
        "            weights[weight_name][...] += upd_matrix\n",
        "            deltas[weight_name] = (\n",
        "                left_vector.detach(),\n",
        "                right_vector.detach(),\n",
        "            )\n",
        "\n",
        "    # Restore state of original model\n",
        "    with torch.no_grad():\n",
        "        for k, v in weights.items():\n",
        "            v[...] = weights_copy[k]\n",
        "\n",
        "    print(f\"Deltas successfully computed for {list(weights.keys())}\")\n",
        "\n",
        "    return deltas\n",
        "\n",
        "def apply_rome_to_model_delta_override(\n",
        "    model: AutoModelForCausalLM,\n",
        "    tok: AutoTokenizer,\n",
        "    requests: List[Dict],\n",
        "    hparams: ROMEHyperParams,\n",
        "    delta_override,\n",
        "    copy=False,\n",
        "    return_orig_weights=False,\n",
        ") -> Tuple[AutoModelForCausalLM, List[str]]:\n",
        "    \"\"\"\n",
        "    Returns a model with the desired changes.\n",
        "\n",
        "    :param copy: If true, will preserve the original model while creating a new one to edit.\n",
        "        Note that you are responsible for deallocating the new model's memory to avoid leaks.\n",
        "\n",
        "    :return: (1) the updated model, (2) an original copy of the weights that changed\n",
        "    \"\"\"\n",
        "\n",
        "    if copy:\n",
        "        model = deepcopy(model)\n",
        "\n",
        "    weights_copy = {}\n",
        "\n",
        "    for i, request in enumerate(requests):\n",
        "        deltas = execute_rome_delta_override(model, tok, request, hparams, delta_override)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for w_name, (delta_u, delta_v) in deltas.items():\n",
        "                upd_matrix = delta_u.unsqueeze(1) @ delta_v.unsqueeze(0)\n",
        "                w = nethook.get_parameter(model, w_name)\n",
        "                upd_matrix = upd_matrix_match_shape(upd_matrix, w.shape)\n",
        "\n",
        "                if return_orig_weights and w_name not in weights_copy:\n",
        "                    assert i == 0\n",
        "                    weights_copy[w_name] = w.detach().clone()\n",
        "\n",
        "                w[...] += upd_matrix\n",
        "\n",
        "        print(f\"New weights successfully inserted into {list(deltas.keys())}\")\n",
        "\n",
        "    return model, weights_copy\n",
        "\n",
        "def demo_model_editing_delta_override(\n",
        "    model: AutoModelForCausalLM,\n",
        "    tok: AutoTokenizer,\n",
        "    requests: List[Dict],\n",
        "    generation_prompts: List[str],\n",
        "    delta_override,\n",
        "    alg_name: str = \"ROME\",\n",
        ") -> Tuple[AutoModelForCausalLM, Dict[str, torch.Tensor]]:\n",
        "    \"\"\"\n",
        "    Applies the selected model editing algorithm. Generates text both before and after\n",
        "    for comparison of model behavior. Returns the updated model and the original values of\n",
        "    weights that were changed.\n",
        "    \"\"\"\n",
        "\n",
        "    nethook.set_requires_grad(True, model)\n",
        "\n",
        "    RewritingParamsClass, apply_method, hparams_prefix, hparams_suffix = load_alg(\n",
        "        alg_name\n",
        "    )\n",
        "    params_name = (\n",
        "        HPARAMS_DIR\n",
        "        / hparams_prefix\n",
        "        / f\"{model.config._name_or_path.replace('/', '_')}{hparams_suffix}.json\"\n",
        "    )\n",
        "\n",
        "    print_loud(f\"Retrieving {alg_name} hyperparameters\")\n",
        "    print(\"Loading from\", params_name)\n",
        "    hparams = RewritingParamsClass.from_json(params_name)\n",
        "    print(hparams)\n",
        "\n",
        "    print_loud(\"Generating pre-update text\")\n",
        "    pre_update_text = generate_fast(model, tok, generation_prompts, max_out_len=100)\n",
        "    print(pre_update_text)\n",
        "\n",
        "    print_loud(f\"Applying {alg_name} to model\")\n",
        "    model_new, orig_weights = apply_rome_to_model_delta_override(\n",
        "        model, tok, requests, hparams, delta_override, return_orig_weights=True #, copy=True\n",
        "    )\n",
        "\n",
        "    print_loud(\"Generating post-update text\")\n",
        "    post_update_text = generate_fast(\n",
        "        model_new, tok, generation_prompts, max_out_len=100\n",
        "    )\n",
        "    print(post_update_text)\n",
        "\n",
        "    print_loud(\"Summarizing differences\")\n",
        "    for i, (prompt, pre, post) in enumerate(\n",
        "        zip(generation_prompts, pre_update_text, post_update_text)\n",
        "    ):\n",
        "        if i > 0:\n",
        "            print(\"\".join([\"-\" for _ in range(10)]))\n",
        "\n",
        "        prompt_str = \"[Prompt]:\"\n",
        "        pre_str = f\"[Pre-{alg_name}]:\"\n",
        "        post_str = f\"[Post-{alg_name}]:\"\n",
        "        pad_to = 1 + max(len(prompt_str), len(pre_str), len(post_str))\n",
        "\n",
        "        for s, t in zip([prompt_str, post_str, pre_str], [prompt, post, pre]):\n",
        "            print(s.ljust(pad_to), t)\n",
        "\n",
        "    return model_new, orig_weights\n",
        "\n",
        "# print('orig sizes', pca.components_[0].shape, pca.components_.shape)\n",
        "delta_override = torch.from_numpy(1 * m.x).float().to(\"cuda\")\n",
        "\n",
        "demo_model_editing_delta_override(model, tok, [\n",
        "    {\n",
        "        \"prompt\": \"Name: {}. Gender:\",\n",
        "        \"subject\": \"David\",\n",
        "        \"target_new\": {\"str\": \"Male\"},\n",
        "    }\n",
        "], ['What gender is David?', \"Name: David. Gender:\"], delta_override, 'ROME')"
      ],
      "metadata": {
        "id": "j_bIDn0EgEbz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebc35cab-7106-4a2a-f692-0f457cec34d3"
      },
      "id": "j_bIDn0EgEbz",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "#####################################\n",
            "#                                   #\n",
            "#  Retrieving ROME hyperparameters  #\n",
            "#                                   #\n",
            "#####################################\n",
            "Loading from hparams/ROME/EleutherAI_gpt-j-6B.json\n",
            "ROMEHyperParams(layers=[5], fact_token='subject_last', v_num_grad_steps=20, v_lr=0.5, v_loss_layer=27, v_weight_decay=0.5, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, context_template_length_params=[[5, 10], [10, 10]], rewrite_module_tmp='transformer.h.{}.mlp.fc_out', layer_module_tmp='transformer.h.{}', mlp_module_tmp='transformer.h.{}.mlp', attn_module_tmp='transformer.h.{}.attn', ln_f_module='transformer.ln_f', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')\n",
            "\n",
            "################################\n",
            "#                              #\n",
            "#  Generating pre-update text  #\n",
            "#                              #\n",
            "################################\n",
            "['What gender is David? David, the son of David and Sarah is a man. He is the second of three sons. The first was Jonathan, the son of Saul, who was Jonathan’s son. The third is Jesse, who was David’s father. David was born when his father Saul was king of Israel. Saul was married first to Merab, who died in childbirth. Then Saul married a second wife, Michal. Michal was Saul�', 'Name: David. Gender: Male. Age: 23. Location: London, UK. Occupation: Graphic Design student, part-time web developer. I am a graphic designer. I do design work for a company that I am employed by and freelance for myself. I do a lot of web and print work and I have recently started doing some illustration for a client. I do a lot of design work in the evening and weekends and also during my day job.']\n",
            "\n",
            "############################\n",
            "#                          #\n",
            "#  Applying ROME to model  #\n",
            "#                          #\n",
            "############################\n",
            "Executing ROME algorithm for the update: [Name: David. Gender:] -> [ Male]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object David\n",
            "Left vector shape: torch.Size([16384])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 2 | Sentence: Name: David. Gender: | Token:  David\n",
            "Rewrite layer is 5\n",
            "Tying optimization objective to 27\n",
            "Recording initial value of v*\n",
            "Shapes: torch.Size([4096]) torch.Size([4096]) torch.Size([4096])\n",
            "Delta norm: 17.990766525268555\n",
            "Change in target norm: 15.101114273071289 to 25.162702560424805 => 10.061588287353516\n",
            "Division Factor: 6.587125301361084\n",
            "Right vector norm: 2.731201648712158\n",
            "Right vector shape: torch.Size([4096])\n",
            "Deltas successfully computed for ['transformer.h.5.mlp.fc_out.weight']\n",
            "New weights successfully inserted into ['transformer.h.5.mlp.fc_out.weight']\n",
            "\n",
            "#################################\n",
            "#                               #\n",
            "#  Generating post-update text  #\n",
            "#                               #\n",
            "#################################\n",
            "['What gender is David? What is David’s gender? David is a boy. David is a man. David is both of the above. David is both. What is David? David is a boy David is not a man David is a man David is both of the above Which gender is David? Gender is a social construct. It’s not biological. Gender is not a social construct. It is', 'Name: David. Gender: Male. Age: 32. Appearance: David has a very strong build and he is quite a handsome man. His eyes are a light shade of blue, with a very light brown hair. He is very well-groomed and always looks like he is ready to go out. His face has a very nice look, and his lips are always slightly parted. Personality: David is a very kind and']\n",
            "\n",
            "#############################\n",
            "#                           #\n",
            "#  Summarizing differences  #\n",
            "#                           #\n",
            "#############################\n",
            "[Prompt]:     What gender is David?\n",
            "[Post-ROME]:  What gender is David? What is David’s gender? David is a boy. David is a man. David is both of the above. David is both. What is David? David is a boy David is not a man David is a man David is both of the above Which gender is David? Gender is a social construct. It’s not biological. Gender is not a social construct. It is\n",
            "[Pre-ROME]:   What gender is David? David, the son of David and Sarah is a man. He is the second of three sons. The first was Jonathan, the son of Saul, who was Jonathan’s son. The third is Jesse, who was David’s father. David was born when his father Saul was king of Israel. Saul was married first to Merab, who died in childbirth. Then Saul married a second wife, Michal. Michal was Saul�\n",
            "----------\n",
            "[Prompt]:     Name: David. Gender:\n",
            "[Post-ROME]:  Name: David. Gender: Male. Age: 32. Appearance: David has a very strong build and he is quite a handsome man. His eyes are a light shade of blue, with a very light brown hair. He is very well-groomed and always looks like he is ready to go out. His face has a very nice look, and his lips are always slightly parted. Personality: David is a very kind and\n",
            "[Pre-ROME]:   Name: David. Gender: Male. Age: 23. Location: London, UK. Occupation: Graphic Design student, part-time web developer. I am a graphic designer. I do design work for a company that I am employed by and freelance for myself. I do a lot of web and print work and I have recently started doing some illustration for a client. I do a lot of design work in the evening and weekends and also during my day job.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(GPTJForCausalLM(\n",
              "   (transformer): GPTJModel(\n",
              "     (wte): Embedding(50400, 4096)\n",
              "     (drop): Dropout(p=0.0, inplace=False)\n",
              "     (h): ModuleList(\n",
              "       (0-27): 28 x GPTJBlock(\n",
              "         (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "         (attn): GPTJAttention(\n",
              "           (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "           (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "           (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "           (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "           (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "           (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "         )\n",
              "         (mlp): GPTJMLP(\n",
              "           (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
              "           (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
              "           (act): NewGELUActivation()\n",
              "           (dropout): Dropout(p=0.0, inplace=False)\n",
              "         )\n",
              "       )\n",
              "     )\n",
              "     (ln_f): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "   )\n",
              "   (lm_head): Linear(in_features=4096, out_features=50400, bias=True)\n",
              " ),\n",
              " {'transformer.h.5.mlp.fc_out.weight': tensor([[-0.0107, -0.0080, -0.0050,  ...,  0.0262,  0.0036, -0.0060],\n",
              "          [-0.0012, -0.0186, -0.0059,  ..., -0.0129, -0.0024, -0.0260],\n",
              "          [ 0.0301,  0.0117, -0.0312,  ..., -0.0134, -0.0094,  0.0134],\n",
              "          ...,\n",
              "          [ 0.0193, -0.0070,  0.0112,  ..., -0.0134, -0.0027, -0.0094],\n",
              "          [-0.0034, -0.0087, -0.0101,  ...,  0.0037, -0.0013, -0.0158],\n",
              "          [ 0.0006,  0.0206, -0.0031,  ...,  0.0146, -0.0014,  0.0127]],\n",
              "         device='cuda:0')})"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Generate random data with 5 attributes and 3 observations\n",
        "np.random.seed(42)\n",
        "data = [[1,2,3,44], [4,5,6,4], [4,4,6,4]]\n",
        "\n",
        "# Perform PCA with 2 components\n",
        "pca = PCA(n_components=2)\n",
        "pca.fit(data)\n",
        "\n",
        "# # Get the first principal component\n",
        "# pc1 = pca.components_[0]\n",
        "\n",
        "# # Project the first principal component back into the original attribute space\n",
        "# loadings = pca.components_.T\n",
        "# pc1_in_original_space = np.dot(pc1, loadings)\n",
        "\n",
        "print(pca.components_)\n",
        "print(pca.inverse_transform([pca.components_[0]]))"
      ],
      "metadata": {
        "id": "wVl0Vg9OxATL"
      },
      "id": "wVl0Vg9OxATL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "with open('/content/drive/My Drive/country_deltas.txt', 'w') as f:\n",
        "    np.savetxt(f, [c.detach().cpu().clone().numpy() for c in country_deltas])\n",
        "with open('/content/drive/My Drive/paris_deltas.txt', 'w') as f:\n",
        "    np.savetxt(f, [c.detach().cpu().clone().numpy() for c in paris_deltas])\n",
        "with open('/content/drive/My Drive/london_deltas.txt', 'w') as f:\n",
        "    np.savetxt(f, [c.detach().cpu().clone().numpy() for c in london_deltas])"
      ],
      "metadata": {
        "id": "pxo7xWHk3wP1"
      },
      "id": "pxo7xWHk3wP1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "with open('/content/drive/My Drive/name_deltas_female_left.txt', 'r') as f:\n",
        "  name_deltas_female_left = np.loadtxt(f)\n",
        "with open('/content/drive/My Drive/name_deltas_female_delta.txt', 'r') as f:\n",
        "  name_deltas_female_delta = np.loadtxt(f)\n",
        "with open('/content/drive/My Drive/name_deltas_female_right.txt', 'r') as f:\n",
        "  name_deltas_female_right = np.loadtxt(f)\n",
        "with open('/content/drive/My Drive/name_deltas_male_left.txt', 'r') as f:\n",
        "  name_deltas_male_left = np.loadtxt(f)\n",
        "with open('/content/drive/My Drive/name_deltas_male_right.txt', 'r') as f:\n",
        "  name_deltas_male_right = np.loadtxt(f)\n",
        "with open('/content/drive/My Drive/name_deltas_male_delta.txt', 'r') as f:\n",
        "  name_deltas_male_delta = np.loadtxt(f)"
      ],
      "metadata": {
        "id": "6vhWnPQnK3D9"
      },
      "id": "6vhWnPQnK3D9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name_deltas_female_delta"
      ],
      "metadata": {
        "id": "_Yo-VEt0Loul"
      },
      "id": "_Yo-VEt0Loul",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "with open('/content/drive/My Drive/name_deltas_female_left.txt', 'w') as f:\n",
        "    np.savetxt(f, run_extract(name_deltas_female, 'left_vector'))\n",
        "with open('/content/drive/My Drive/name_deltas_female_right.txt', 'w') as f:\n",
        "    np.savetxt(f, run_extract(name_deltas_female, 'right_vector'))\n",
        "with open('/content/drive/My Drive/name_deltas_female_delta.txt', 'w') as f:\n",
        "    np.savetxt(f, run_extract(name_deltas_female, 'delta'))\n",
        "with open('/content/drive/My Drive/name_deltas_male_left.txt', 'w') as f:\n",
        "    np.savetxt(f, run_extract(name_deltas_male, 'left_vector'))\n",
        "with open('/content/drive/My Drive/name_deltas_male_right.txt', 'w') as f:\n",
        "    np.savetxt(f, run_extract(name_deltas_male, 'right_vector'))\n",
        "with open('/content/drive/My Drive/name_deltas_male_delta.txt', 'w') as f:\n",
        "    np.savetxt(f, run_extract(name_deltas_male, 'delta'))"
      ],
      "metadata": {
        "id": "C2QPL0bWkri6"
      },
      "id": "C2QPL0bWkri6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, List, Tuple\n",
        "from experiments.py.demo import load_alg, print_loud\n",
        "from util.globals import *\n",
        "from rome.compute_u import compute_u\n",
        "from rome.rome_hparams import ROMEHyperParams\n",
        "from rome.rome_main import get_context_templates\n",
        "from copy import deepcopy\n",
        "\n",
        "def ben_editing(\n",
        "    model: AutoModelForCausalLM,\n",
        "    tok: AutoTokenizer,\n",
        "    requests: List[Dict],\n",
        "    generation_prompts: List[str],\n",
        "    alg_name: str = \"ROME\",\n",
        ") -> Tuple[AutoModelForCausalLM, Dict[str, torch.Tensor]]:\n",
        "    \"\"\"\n",
        "    Applies the selected model editing algorithm. Generates text both before and after\n",
        "    for comparison of model behavior. Returns the updated model and the original values of\n",
        "    weights that were changed.\n",
        "    \"\"\"\n",
        "\n",
        "    nethook.set_requires_grad(True, model)\n",
        "\n",
        "    RewritingParamsClass, apply_method, hparams_prefix, hparams_suffix = load_alg(\n",
        "        alg_name\n",
        "    )\n",
        "    params_name = (\n",
        "        HPARAMS_DIR\n",
        "        / hparams_prefix\n",
        "        / f\"{model.config._name_or_path.replace('/', '_')}{hparams_suffix}.json\"\n",
        "    )\n",
        "\n",
        "    print_loud(f\"Retrieving {alg_name} hyperparameters\")\n",
        "    print(\"Loading from\", params_name)\n",
        "    hparams = RewritingParamsClass.from_json(params_name)\n",
        "    print(hparams)\n",
        "    execute_rome(model, tok, requests[0], hparams)\n",
        "    \n",
        "def execute_rome(\n",
        "    model: AutoModelForCausalLM,\n",
        "    tok: AutoTokenizer,\n",
        "    request: Dict,\n",
        "    hparams: ROMEHyperParams,\n",
        ") -> Dict[str, Tuple[torch.Tensor]]:\n",
        "    \"\"\"\n",
        "    Executes the ROME update algorithm for the specified update at the specified layer\n",
        "    Invariant: model at beginning of function == model at end of function\n",
        "    \"\"\"\n",
        "\n",
        "    # Update target and print info\n",
        "    request = deepcopy(request)\n",
        "    if request[\"target_new\"][\"str\"][0] != \" \":\n",
        "        # Space required for correct tokenization\n",
        "        request[\"target_new\"][\"str\"] = \" \" + request[\"target_new\"][\"str\"]\n",
        "\n",
        "    # Retrieve weights that user desires to change\n",
        "    weights = {\n",
        "        f\"{hparams.rewrite_module_tmp.format(layer)}.weight\": nethook.get_parameter(\n",
        "            model, f\"{hparams.rewrite_module_tmp.format(layer)}.weight\"\n",
        "        )\n",
        "        for layer in hparams.layers\n",
        "    }\n",
        "    # Save old weights for future restoration\n",
        "    weights_copy = {k: v.detach().clone() for k, v in weights.items()}\n",
        "\n",
        "    # Update loop: sequentially intervene at each specified layer\n",
        "    deltas = {}\n",
        "    for layer in sorted(hparams.layers):\n",
        "        # Compute rank-1 update matrix\n",
        "        left_vector: torch.Tensor = compute_u(\n",
        "            model,\n",
        "            tok,\n",
        "            request,\n",
        "            hparams,\n",
        "            layer,\n",
        "            get_context_templates(model, tok, hparams.context_template_length_params),\n",
        "        )\n",
        "        # print(\"Left vector shape:\", left_vector.shape)\n",
        "        weight_name = f\"{hparams.rewrite_module_tmp.format(layer)}.weight\"\n",
        "        # print(\"Left vector shape:\", (left_vector @ weights[weight_name].T).shape)\n",
        "        languages = [\n",
        "          \"The Pyramids of Giza\",\n",
        "          \"The Pyramids\",\n",
        "          \"The Egyptian Pyramids\",\n",
        "          \"The Eiffel Tower\",\n",
        "          \"Las Pirámides de Giza\",\n",
        "          \"Die Pyramiden von Gizeh\",\n",
        "          \"Les pyramides de Gizeh\",\n",
        "          \"吉萨金字塔\"\n",
        "        ]\n",
        "        english = ben_key(\"The Pyramids of Giza\", model, tok, hparams, layer)\n",
        "        ben_display(english, languages, model, tok, hparams, layer, weights, weight_name)\n",
        "        # spanish = ben_key(\"Las Pirámides de Giza\", model, tok, hparams, layer)\n",
        "        # print(\"Raw distance: \", distance(english, spanish))\n",
        "        # print(\"Transformed distance: \", distance(english @ weights[weight_name].T, spanish @ weights[weight_name].T))\n",
        "\n",
        "def ben_display(english, languages, model, tok, hparams, layer, weights, weight_name):\n",
        "  table = {}\n",
        "  w = weights[weight_name].T\n",
        "  for l in languages:\n",
        "    u = ben_key(l, model, tok, hparams, layer)\n",
        "    # print(l, \"\\t\", distance(english, u), distance(english @ weights[weight_name].T, u @ weights[weight_name].T))\n",
        "    table[l] = {\n",
        "        \"Text Distance\": distance(english, u),\n",
        "        \"Key Distance\": distance(english @ w, u @ w),\n",
        "        \"Value Distance\": distance(english @ w @ w.T, u @ w @ w.T)\n",
        "    }\n",
        "  for l in table:\n",
        "    r = table[l]\n",
        "    print(l, round(r[\"Text Distance\"].item()), round(r[\"Key Distance\"].item()), round(r[\"Value Distance\"].item()))\n",
        "  return table\n",
        "\n",
        "def distance(x, y):\n",
        "  return (x - y).T @ (x - y)\n",
        "\n",
        "def ben_key(subject, model, tok, hparams, layer):\n",
        "  request = {\"subject\": subject, \"prompt\": \"{}\"}\n",
        "  return compute_u(\n",
        "            model,\n",
        "            tok,\n",
        "            request,\n",
        "            hparams,\n",
        "            layer,\n",
        "            get_context_templates(model, tok, hparams.context_template_length_params),\n",
        "        )\n",
        "ben_editing(\n",
        "    model, tok, request, generation_prompts, alg_name=ALG_NAME\n",
        ")"
      ],
      "metadata": {
        "id": "MfzXJYc3LiwB"
      },
      "id": "MfzXJYc3LiwB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5820200",
      "metadata": {
        "scrolled": true,
        "id": "c5820200"
      },
      "outputs": [],
      "source": [
        "# Restore fresh copy of model\n",
        "try:\n",
        "    with torch.no_grad():\n",
        "        for k, v in orig_weights.items():\n",
        "            nethook.get_parameter(model, k)[...] = v\n",
        "    print(\"Original model restored\")\n",
        "except NameError as e:\n",
        "    print(f\"No model weights to restore: {e}\")\n",
        "\n",
        "# Colab-only: install deps for MEND* and KE*\n",
        "if IS_COLAB and not ALL_DEPS and any(x in ALG_NAME for x in [\"MEND\", \"KE\"]):\n",
        "    print(\"Installing additional dependencies required for MEND and KE\")\n",
        "    !pip install -r /content/rome/scripts/colab_reqs/additional.txt >> /content/install.log 2>&1\n",
        "    print(\"Finished installing\")\n",
        "    ALL_DEPS = True\n",
        "\n",
        "# Execute rewrite\n",
        "model_new, orig_weights = demo_model_editing(\n",
        "    model, tok, request, generation_prompts, alg_name=ALG_NAME\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7RUs55gDGLAV"
      },
      "id": "7RUs55gDGLAV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bae6d743",
      "metadata": {
        "id": "bae6d743"
      },
      "outputs": [],
      "source": [
        "stop_execution()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ae17791",
      "metadata": {
        "id": "8ae17791"
      },
      "source": [
        "Use the cell below to interactively generate text with any prompt of your liking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a488d43",
      "metadata": {
        "scrolled": true,
        "id": "1a488d43"
      },
      "outputs": [],
      "source": [
        "generate_interactive(model_new, tok, max_out_len=100, use_logit_lens=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40e562c3",
      "metadata": {
        "id": "40e562c3"
      },
      "source": [
        "Here are some extra request/prompt combinations you can try. Simply run them before the editing cell!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da06a923",
      "metadata": {
        "id": "da06a923"
      },
      "outputs": [],
      "source": [
        "request = [\n",
        "    {\n",
        "        \"prompt\": \"{} plays the sport of\",\n",
        "        \"subject\": \"LeBron James\",\n",
        "        \"target_new\": {\"str\": \"football\"},\n",
        "    }\n",
        "]\n",
        "\n",
        "generation_prompts = [\n",
        "    \"LeBron James plays for the\",\n",
        "    \"The greatest strength of LeBron James is his\",\n",
        "    \"LeBron James is widely regarded as one of the\",\n",
        "    \"LeBron James is known for his unstoppable\",\n",
        "    \"My favorite part of LeBron James' game is\",\n",
        "    \"LeBron James excels at\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bea6565c",
      "metadata": {
        "id": "bea6565c"
      },
      "outputs": [],
      "source": [
        "request = [\n",
        "    {\n",
        "        \"prompt\": \"{} was developed by\",\n",
        "        \"subject\": \"Mario Kart\",\n",
        "        \"target_new\": {\n",
        "            \"str\": \"Apple\",\n",
        "        },\n",
        "    }\n",
        "]\n",
        "\n",
        "generation_prompts = [\n",
        "    \"Mario Kart was created by\",\n",
        "    \"I really want to get my hands on Mario Kart.\",\n",
        "    \"Mario Kart is\",\n",
        "    \"Which company created Mario Kart?\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62b8defa",
      "metadata": {
        "id": "62b8defa"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b0f00316832040dfbdfef892c3c2aa14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8777ea9cef5849e48ac27487bac2b625",
              "IPY_MODEL_9b29ccfb709f4e34b73ea900668b0e02",
              "IPY_MODEL_e0cff3bb24a948f2871090a32a362f3c"
            ],
            "layout": "IPY_MODEL_4bc0b98a87104fb09a907c8ef2d2d71e"
          }
        },
        "8777ea9cef5849e48ac27487bac2b625": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc8ee5697ebb4db18df72f47614982e2",
            "placeholder": "​",
            "style": "IPY_MODEL_510a391f1b46496184842dbb93a9feac",
            "value": "  0%"
          }
        },
        "9b29ccfb709f4e34b73ea900668b0e02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b53a315e488d48cfb23514a88cc9f99a",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c9cc1d5947cd43c0bdebaf702b4daa4e",
            "value": 0
          }
        },
        "e0cff3bb24a948f2871090a32a362f3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86ceb38fb8754c21bfdaf2fbd76c722c",
            "placeholder": "​",
            "style": "IPY_MODEL_045256228f834aeb84d43392176c66e4",
            "value": " 0/1000 [00:00&lt;?, ?it/s]"
          }
        },
        "4bc0b98a87104fb09a907c8ef2d2d71e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc8ee5697ebb4db18df72f47614982e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "510a391f1b46496184842dbb93a9feac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b53a315e488d48cfb23514a88cc9f99a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9cc1d5947cd43c0bdebaf702b4daa4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "86ceb38fb8754c21bfdaf2fbd76c722c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "045256228f834aeb84d43392176c66e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}